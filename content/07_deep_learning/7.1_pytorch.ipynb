{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d33ff2fa-192a-4864-ac79-61c786d8f2cd",
   "metadata": {},
   "source": [
    "# 7.1 PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdb013a-d23a-405d-88eb-28290aecb3b1",
   "metadata": {},
   "source": [
    "This notebook is an adaptation of the PyTorch Tutorial of Patrick Loeber which you can find [here](https://github.com/python-engineer/pytorchTutorial) (MIT License - Copyright (c) 2020 Patrick Loeber)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718414fa-fd14-49d3-ae3d-97726d7ffb1f",
   "metadata": {},
   "source": [
    "What is PyTorch?\n",
    "- One of the most popular modern deep learning frameworks (next to Tensorflow, JAX)\n",
    "\n",
    "Check out this Free Online Course to learn more:\n",
    "- [Deep learning with PyTorch Free Online Course](https://www.youtube.com/watch?v=c36lUUr864M&t=8387s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6ec89cfe-7d35-4097-86d8-270e75fb95f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7432de24-4d80-405c-a63d-5dade646033e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd95cbd-4b58-4cc5-a813-1b83cc021a03",
   "metadata": {},
   "source": [
    "## Tensor Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56acb965-e71e-48d2-a80b-170360760802",
   "metadata": {},
   "source": [
    "Tensors are generalizations of matrices to the N-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3220b13b-31f8-4738-8b26-e03a20c35806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-1.9930e-03,  4.5640e-41,  8.0532e-39],\n",
      "          [ 3.0813e-41, -3.5455e-31,  4.5640e-41]],\n",
      "\n",
      "         [[-4.7037e-22,  4.5640e-41, -1.3589e-03],\n",
      "          [ 4.5640e-41, -1.0792e-03,  4.5640e-41]]],\n",
      "\n",
      "\n",
      "        [[[-1.0841e+32,  4.5639e-41, -1.0841e+32],\n",
      "          [ 4.5639e-41, -1.2222e-03,  4.5640e-41]],\n",
      "\n",
      "         [[-3.5455e-31,  4.5640e-41, -3.5456e-31],\n",
      "          [ 4.5640e-41, -3.5456e-31,  4.5640e-41]]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(2, 2, 2, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e30c778-3392-4e54-9ff5-5389543b61cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4497, 0.3614, 0.5639, 0.0315, 0.7798],\n",
      "        [0.0888, 0.6610, 0.2116, 0.3251, 0.9207],\n",
      "        [0.2005, 0.8838, 0.3763, 0.6784, 0.9023]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3, 5)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8aa760cc-a166-4fd6-a05d-a7605f9a843f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(2, 2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05d397cb-78fc-4719-afd9-5a41e9c4824e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d450ccd3-7280-4a90-8c1c-c2a19628bc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int32\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, dtype=torch.int)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6c8d58a-4382-459f-a555-07e2d07d410f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e3aa32d-1d8c-44eb-a54c-513e2e1cc9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.5000, 0.1000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([2.5, 0.1])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8843caa4-3fb8-4ae4-800e-5b0ef7e7e240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1585, 0.8353],\n",
      "        [0.8681, 0.8932]])\n",
      "tensor([[0.7576, 0.6090],\n",
      "        [0.5286, 0.6291]])\n",
      "tensor([[0.9161, 1.4443],\n",
      "        [1.3967, 1.5223]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 2)\n",
    "y = torch.rand(2, 2)\n",
    "z = x + y\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6e64bd0-c4de-433d-ad04-8b9d00823146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8628, 0.5960, 0.3563],\n",
      "        [0.5111, 0.3448, 0.8360],\n",
      "        [0.5998, 0.1393, 0.9871],\n",
      "        [0.5946, 0.8876, 0.7532],\n",
      "        [0.3101, 0.9496, 0.4567]])\n",
      "tensor([0.8628, 0.5111, 0.5998, 0.5946, 0.3101])\n",
      "0.34479236602783203\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "print(x[:, 0])\n",
    "print(x[1,1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36b091fb-60cc-45d3-8557-524823ba9be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6380, 0.8570, 0.1222, 0.1891],\n",
      "        [0.3010, 0.2032, 0.8739, 0.8386],\n",
      "        [0.1223, 0.6211, 0.3750, 0.0056],\n",
      "        [0.5722, 0.5467, 0.0217, 0.6983]])\n",
      "tensor([0.6380, 0.8570, 0.1222, 0.1891, 0.3010, 0.2032, 0.8739, 0.8386, 0.1223,\n",
      "        0.6211, 0.3750, 0.0056, 0.5722, 0.5467, 0.0217, 0.6983])\n",
      "tensor([[0.6380, 0.8570, 0.1222, 0.1891, 0.3010, 0.2032, 0.8739, 0.8386],\n",
      "        [0.1223, 0.6211, 0.3750, 0.0056, 0.5722, 0.5467, 0.0217, 0.6983]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4, 4)\n",
    "print(x)\n",
    "y = x.view(16)\n",
    "print(y)\n",
    "y = x.view(-1, 8)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "780c3730-2c84-48a0-9f4c-d9cc6c09e043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'numpy.ndarray'>\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(type(a))\n",
    "b = a.numpy()\n",
    "print(type(b))\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "# both objects share the same memory location when the tensor is on cpu\n",
    "a += 1\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53e703c7-4795-4159-883e-17dd75cf1758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "print(a)\n",
    "b = torch.from_numpy(a)\n",
    "print(b)\n",
    "a += 1\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43e3681c-d571-408b-8725-f163e9962b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5, requires_grad=True) # calculate gradients for this vector in the optimization step\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d7d9f1-7f76-4756-9e51-b66b315b17bd",
   "metadata": {},
   "source": [
    "## Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b442ef2-8591-442f-a6c5-cfc71e477dc1",
   "metadata": {},
   "source": [
    "Calculating gradients automatically for the optimization. PyTorch will create a computation graph for backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9448628e-6f16-4b6c-9468-04cb946eff36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.0892,  0.1571, -0.3457], requires_grad=True)\n",
      "tensor([-0.0892,  2.1571,  1.6543], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "print(x)\n",
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b287663-ea93-4bc9-a5a0-90a1e8e6592c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0159, 9.3060, 5.4733], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = (y*y*2)\n",
    "# z = z.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ae1aa24-2a52-4109-80da-11f941f73e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.tensor([0.1, 1.0, 0.001], dtype=torch.float32)\n",
    "z.backward(v) # dz/dx -> chain rule dz/dy * dy/dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bd53c80-a475-4f8b-ba6e-ea4af585c5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3.5674e-02,  8.6283e+00,  6.6171e-03])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "935b3e42-289b-43f2-b9d7-32b32713ae84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0892,  2.1571,  1.6543])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y = x + 2\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ca6fc08-69ff-498f-bc25-80ad334ce71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([6., 6., 6., 6.])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(4, requires_grad=True)\n",
    "\n",
    "for epoch in range(2):\n",
    "    model_output = (weights*3).sum()\n",
    "    model_output.backward()\n",
    "    print(weights.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2b416b8-39ee-4fc9-8432-b4d794327753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(4, requires_grad=True)\n",
    "\n",
    "for epoch in range(2):\n",
    "    model_output = (weights*3).sum()\n",
    "    model_output.backward()\n",
    "    print(weights.grad)\n",
    "    weights.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97686ec7-03c0-406f-9a00-5c043bad6eb6",
   "metadata": {},
   "source": [
    "## Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "546d050b-59ef-447f-84ce-2c052f8d5699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<PowBackward0>)\n",
      "tensor(-2.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)\n",
    "w = torch.tensor(1.0, requires_grad=True)\n",
    " \n",
    "# forward pass and compute loss\n",
    "y_hat = w * x\n",
    "loss = (y_hat - y)**2\n",
    "print(loss)\n",
    "\n",
    "# backward pass\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "\n",
    "# update weights\n",
    "# next forward and backward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a093fa8-2856-4cc3-86a6-f814c900b73c",
   "metadata": {},
   "source": [
    "## Gradient Descent using Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56591d4-2543-4b17-ae2f-606bd6ff282a",
   "metadata": {},
   "source": [
    "Linear Regression: Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9b0ee2f-aaac-4446-9d35-61c65aeb64e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n",
      "epoch 1: w = 0.300, loss = 30.00000000\n",
      "epoch 3: w = 0.772, loss = 15.66018677\n",
      "epoch 5: w = 1.113, loss = 8.17471600\n",
      "epoch 7: w = 1.359, loss = 4.26725292\n",
      "epoch 9: w = 1.537, loss = 2.22753215\n",
      "epoch 11: w = 1.665, loss = 1.16278565\n",
      "epoch 13: w = 1.758, loss = 0.60698175\n",
      "epoch 15: w = 1.825, loss = 0.31684822\n",
      "epoch 17: w = 1.874, loss = 0.16539653\n",
      "epoch 19: w = 1.909, loss = 0.08633806\n",
      "Prediction after training: f(5) = 9.612\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# f = w * x\n",
    "\n",
    "# f = 2 * x\n",
    "X = np.array([1, 2, 3, 4], dtype=np.float32) # feature vector\n",
    "Y = np.array([2, 4, 6, 8], dtype=np.float32) # label vector w. ground truth\n",
    "w = 0.0\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss = MSE\n",
    "def loss(y, y_predicted):\n",
    "    return ((y_predicted -y)**2).mean()\n",
    "\n",
    "# gradient\n",
    "# MSE = 1/N * (w*x-y)**2\n",
    "# dJ/dw = 1/N 2x (w*x-y)\n",
    "def gradient(x, y, y_predicted):\n",
    "    return np.dot(2 * x, y_predicted-y)/len(x)\n",
    "\n",
    "print(f\"Prediction before training: f(5) = {forward(5):.3f}\")\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    # prediction = forward pass\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradients = backward pass\n",
    "    dw = gradient(X, Y, y_pred)\n",
    "    \n",
    "    # update weights\n",
    "    w -= learning_rate * dw\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        print(f\"epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}\")\n",
    "        \n",
    "print(f\"Prediction after training: f(5) = {forward(5):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "772e51d8-cf09-4e64-9fdd-4248cbb838ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n",
      "epoch 1: w = 0.300, loss = 30.00000000\n",
      "epoch 3: w = 0.772, loss = 15.66018772\n",
      "epoch 5: w = 1.113, loss = 8.17471695\n",
      "epoch 7: w = 1.359, loss = 4.26725292\n",
      "epoch 9: w = 1.537, loss = 2.22753215\n",
      "epoch 11: w = 1.665, loss = 1.16278565\n",
      "epoch 13: w = 1.758, loss = 0.60698116\n",
      "epoch 15: w = 1.825, loss = 0.31684780\n",
      "epoch 17: w = 1.874, loss = 0.16539653\n",
      "epoch 19: w = 1.909, loss = 0.08633806\n",
      "Prediction after training: f(5) = 9.612\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# f = w * x\n",
    "\n",
    "# f = 2 * x\n",
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32) # feature vector\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32) # label vector w. ground truth\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss = MSE\n",
    "def loss(y, y_predicted):\n",
    "    return ((y_predicted -y)**2).mean()\n",
    "\n",
    "print(f\"Prediction before training: f(5) = {forward(5):.3f}\")\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    # prediction = forward pass\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradients = backward pass\n",
    "    l.backward() # dl/dw\n",
    "    \n",
    "    # update weights\n",
    "    with torch.no_grad(): # exclude from computational graph\n",
    "        w -= learning_rate * w.grad \n",
    "    \n",
    "    # zero gradients\n",
    "    w.grad.zero_()\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        print(f\"epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}\")\n",
    "        \n",
    "print(f\"Prediction after training: f(5) = {forward(5):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af832ae-0e4d-45ca-b15b-0bba54f28b6a",
   "metadata": {},
   "source": [
    "## PyTorch Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe14bf6-ad74-4978-b619-5e1be030dc47",
   "metadata": {},
   "source": [
    "1) Design model (input_size, output_size, forward pass)\n",
    "2) Construct loss and optimizer\n",
    "3) Training loop\n",
    "   - forward pass: compute prediction\n",
    "   - backward pass: compute gradients\n",
    "   - update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0cc7ed0b-af73-4966-8098-3cd4294d3326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n",
      "epoch 1: w = 0.300, loss = 30.00000000\n",
      "epoch 3: w = 0.772, loss = 15.66018772\n",
      "epoch 5: w = 1.113, loss = 8.17471695\n",
      "epoch 7: w = 1.359, loss = 4.26725292\n",
      "epoch 9: w = 1.537, loss = 2.22753215\n",
      "epoch 11: w = 1.665, loss = 1.16278565\n",
      "epoch 13: w = 1.758, loss = 0.60698116\n",
      "epoch 15: w = 1.825, loss = 0.31684780\n",
      "epoch 17: w = 1.874, loss = 0.16539653\n",
      "epoch 19: w = 1.909, loss = 0.08633806\n",
      "Prediction after training: f(5) = 9.612\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "# f = w * x\n",
    "\n",
    "# f = 2 * x\n",
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32) # feature vector\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32) # label vector w. ground truth\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss = MSE\n",
    "\n",
    "\n",
    "print(f\"Prediction before training: f(5) = {forward(5):.3f}\")\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_epochs = 20\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD([w], lr=learning_rate) # stochastic gradient descent\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # prediction = forward pass\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradients = backward pass\n",
    "    l.backward() # dl/dw\n",
    "    \n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        print(f\"epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}\")\n",
    "        \n",
    "print(f\"Prediction after training: f(5) = {forward(5):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b61efcaf-b5ec-4891-8d14-f9d10d8a8a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n",
      "Prediction before training: f(5) = 4.729\n",
      "epoch 1: w = 1.104, loss = 8.33417797\n",
      "epoch 3: w = 1.353, loss = 4.35049200\n",
      "epoch 5: w = 1.532, loss = 2.27098441\n",
      "epoch 7: w = 1.662, loss = 1.18546796\n",
      "epoch 9: w = 1.756, loss = 0.61882126\n",
      "epoch 11: w = 1.824, loss = 0.32302868\n",
      "epoch 13: w = 1.873, loss = 0.16862285\n",
      "epoch 15: w = 1.908, loss = 0.08802202\n",
      "epoch 17: w = 1.933, loss = 0.04594808\n",
      "epoch 19: w = 1.952, loss = 0.02398521\n",
      "Prediction after training: f(5) = 9.796\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "# f = w * x\n",
    "\n",
    "# f = 2 * x\n",
    "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32) # feature vector\n",
    "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32) # label vector w. ground truth\n",
    "\n",
    "X_test = torch.tensor([5], dtype=torch.float32)\n",
    "n_samples, n_features = X.shape\n",
    "print(n_samples, n_features)\n",
    "\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, bias):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        # define layers\n",
    "        self.lin = nn.Linear(input_dim, output_dim, bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "    \n",
    "model = LinearRegression(input_size, output_size, False)\n",
    "\n",
    "print(f\"Prediction before training: f(5) = {model(X_test).item():.3f}\")\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_epochs = 20\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) # stochastic gradient descent\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # prediction = forward pass\n",
    "    y_pred = model(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradients = backward pass\n",
    "    l.backward() # dl/dw\n",
    "    \n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        [w,] = model.parameters()\n",
    "        print(f\"epoch {epoch+1}: w = {w[0][0].item():.3f}, loss = {l:.8f}\")\n",
    "        \n",
    "print(f\"Prediction after training: f(5) = {model(X_test).item():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49889872-2d91-42af-9722-6c2edeaa0f23",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aec9886-b81a-4d88-aeb5-f3ed421f2ffa",
   "metadata": {},
   "source": [
    "1) Design model (input_size, output_size, forward pass)\n",
    "2) Construct loss and optimizer\n",
    "3) Training loop\n",
    "   - forward pass: compute prediction\n",
    "   - backward pass: compute gradients\n",
    "   - update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61095285-3b4e-4337-b433-9fb69d77d57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10, loss = 4468.4438\n",
      "epoch:20, loss = 3330.6206\n",
      "epoch:30, loss = 2507.8462\n",
      "epoch:40, loss = 1912.2266\n",
      "epoch:50, loss = 1480.6027\n",
      "epoch:60, loss = 1167.5226\n",
      "epoch:70, loss = 940.2293\n",
      "epoch:80, loss = 775.0817\n",
      "epoch:90, loss = 654.9987\n",
      "epoch:100, loss = 567.6231\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 0) prepare data\n",
    "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=1)\n",
    "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
    "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
    "y = y.view(y.shape[0], 1)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "# 1) model\n",
    "input_size = n_features\n",
    "output_size = 1\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "# 2) loss and optimizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 3) training loop\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # forward pass and loss\n",
    "    y_predicted = model(X)\n",
    "    loss = criterion(y_predicted, y)\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"epoch:{epoch+1}, loss = {loss.item():.4f}\")\n",
    "        \n",
    "# plot\n",
    "predicted = model(X).detach().numpy()\n",
    "plt.plot(X_numpy, y_numpy, \"ro\")\n",
    "plt.plot(X_numpy, predicted, \"b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816025f3-c171-4cb0-9514-2bfaf8152138",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88111bd6-20d4-417c-9e7d-1164917fd363",
   "metadata": {},
   "source": [
    "1) Design model (input_size, output_size, forward pass)\n",
    "2) Construct loss and optimizer\n",
    "3) Training loop\n",
    "   - forward pass: compute prediction\n",
    "   - backward pass: compute gradients\n",
    "   - update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df5829fc-3d44-453e-aff3-0d211a8aebe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569 30\n",
      "epoch 10, loss = 0.6756\n",
      "epoch 20, loss = 0.5385\n",
      "epoch 30, loss = 0.4556\n",
      "epoch 40, loss = 0.4001\n",
      "epoch 50, loss = 0.3601\n",
      "epoch 60, loss = 0.3297\n",
      "epoch 70, loss = 0.3056\n",
      "epoch 80, loss = 0.2859\n",
      "epoch 90, loss = 0.2696\n",
      "epoch 100, loss = 0.2557\n",
      "accuracy = 0.9035\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 0) prepare data\n",
    "bc = datasets.load_breast_cancer()\n",
    "X, y = bc.data, bc.target\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "print(n_samples, n_features)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "# scale\n",
    "sc = StandardScaler() # 0 mean unit variance\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)\n",
    "\n",
    "# 1) model\n",
    "# f = wx + b, sigmoid at the end\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_predicted = torch.sigmoid(self.linear(x))\n",
    "        return y_predicted\n",
    "    \n",
    "model = LogisticRegression(n_features)\n",
    "\n",
    "# 2) loss and optimizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 3) training loop\n",
    "n_epochs = 100\n",
    "for epoch in range(n_epochs):\n",
    "    # forward pass and loss\n",
    "    y_predicted = model(X_train)\n",
    "    loss = criterion(y_predicted, y_train)\n",
    "\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # updates\n",
    "    optimizer.step()\n",
    "    \n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"epoch {epoch+1}, loss = {loss.item():.4f}\")\n",
    "              \n",
    "with torch.no_grad():\n",
    "    y_predicted = model(X_test)\n",
    "    y_predicted_cls = y_predicted.round()\n",
    "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
    "    print(f\"accuracy = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc822bee-5a50-4f19-8808-f0e1f875b41d",
   "metadata": {},
   "source": [
    "## Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0fa151-dadb-4d11-bceb-07054b73b459",
   "metadata": {},
   "source": [
    "Gradient calculations on whole training dataset is very time-consuming. Better way is to divide samples in so called batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4fa41b5b-f6be-4f42-b449-671caddee64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b31213f-ecae-4707-bb31-e5a12c349096",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WineDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        # data loading\n",
    "        xy = np.loadtxt(\"../datasets/wine.csv\", delimiter=\",\", dtype=np.float32, skiprows=1)\n",
    "        self.x = torch.from_numpy(xy[:, 1:])\n",
    "        self.y = torch.from_numpy(xy[:, [0]]) # n_samples, 1\n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # dataset[0]\n",
    "        return self.x[index], self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        # len(dataset)\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dbe4eacf-1509-41eb-be84-49ec407f4055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03]) tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "dataset = WineDataset()\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "67578d0b-a8ab-42fa-829e-08aefbe5e0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset=dataset, batch_size=4, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2978b5f3-a690-4437-9959-713a6f568f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4390e+01, 1.8700e+00, 2.4500e+00, 1.4600e+01, 9.6000e+01, 2.5000e+00,\n",
      "         2.5200e+00, 3.0000e-01, 1.9800e+00, 5.2500e+00, 1.0200e+00, 3.5800e+00,\n",
      "         1.2900e+03],\n",
      "        [1.3520e+01, 3.1700e+00, 2.7200e+00, 2.3500e+01, 9.7000e+01, 1.5500e+00,\n",
      "         5.2000e-01, 5.0000e-01, 5.5000e-01, 4.3500e+00, 8.9000e-01, 2.0600e+00,\n",
      "         5.2000e+02],\n",
      "        [1.3080e+01, 3.9000e+00, 2.3600e+00, 2.1500e+01, 1.1300e+02, 1.4100e+00,\n",
      "         1.3900e+00, 3.4000e-01, 1.1400e+00, 9.4000e+00, 5.7000e-01, 1.3300e+00,\n",
      "         5.5000e+02],\n",
      "        [1.3050e+01, 3.8600e+00, 2.3200e+00, 2.2500e+01, 8.5000e+01, 1.6500e+00,\n",
      "         1.5900e+00, 6.1000e-01, 1.6200e+00, 4.8000e+00, 8.4000e-01, 2.0100e+00,\n",
      "         5.1500e+02]]) tensor([[1.],\n",
      "        [3.],\n",
      "        [3.],\n",
      "        [2.]])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(dataloader)\n",
    "data = dataiter.next()\n",
    "features, labels = data\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f590a3da-ac85-4645-b6a4-bc88d8d5fd7c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178 45\n",
      "epoch 1/2, step 5/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 10/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 15/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 20/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 25/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 30/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 35/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 40/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 45/45, inputs torch.Size([2, 13])\n",
      "epoch 2/2, step 5/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 10/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 15/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 20/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 25/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 30/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 35/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 40/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 45/45, inputs torch.Size([2, 13])\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "n_epochs = 2\n",
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples/4)\n",
    "print(total_samples, n_iterations)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        # forward backward, update\n",
    "        if (i+1) % 5 == 0:\n",
    "            print(f\"epoch {epoch+1}/{n_epochs}, step {i+1}/{n_iterations}, inputs {inputs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b904bb-f03d-4436-8d87-996789917a78",
   "metadata": {},
   "source": [
    "## Dataset Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d421de70-52bd-4af8-bb86-26227d23580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "69023c58-4331-46c2-bfdf-3ac8b219f8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WineDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        # data loading\n",
    "        xy = np.loadtxt(\"../datasets/wine.csv\", delimiter=\",\", dtype=np.float32, skiprows=1)\n",
    "        self.x = xy[:, 1:]\n",
    "        self.y = xy[:, [0]] # n_samples, 1\n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # dataset[0]\n",
    "        sample = self.x[index], self.y[index]\n",
    "    \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample\n",
    "        \n",
    "    def __len__(self):\n",
    "        # len(dataset)\n",
    "        return self.n_samples\n",
    "    \n",
    "    \n",
    "class ToTensor:\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
    "    \n",
    "\n",
    "class MulTransform:\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        inputs *= self.factor\n",
    "        return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "02e3bb40-9c90-4ee9-b23a-47cfe6d407d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "dataset = WineDataset(transform=ToTensor())\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features)\n",
    "print(type(features), type(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "48cdb8dc-1998-4d58-a5e9-5335a1660024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.8460e+01, 3.4200e+00, 4.8600e+00, 3.1200e+01, 2.5400e+02, 5.6000e+00,\n",
      "        6.1200e+00, 5.6000e-01, 4.5800e+00, 1.1280e+01, 2.0800e+00, 7.8400e+00,\n",
      "        2.1300e+03])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(2)])\n",
    "dataset = WineDataset(transform=composed)\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features)\n",
    "print(type(features), type(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ace5ec-3f03-43ec-93fc-a6f4bf8eebeb",
   "metadata": {},
   "source": [
    "## Softmax & Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b5d9c5e2-d90b-4bde-a98d-7a4d1b367206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax numpy: [0.65900114 0.24243297 0.09856589]\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "x = np.array([2.0, 1.0, 0.1])\n",
    "outputs = softmax(x)\n",
    "print(\"Softmax numpy:\", outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "19d85185-0094-40df-a139-4f494d45008a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax torch: tensor([0.6590, 0.2424, 0.0986])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([2.0, 1.0, 0.1])\n",
    "outputs = torch.softmax(x, dim=0)\n",
    "print(\"Softmax torch:\", outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "63916baa-1b9a-416f-902d-5a2b424a5ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1 numpy: 0.3567\n",
      "Loss 2 numpy: 2.3026\n"
     ]
    }
   ],
   "source": [
    "def cross_entropy(actual, predicted):\n",
    "    loss = -np.sum(actual * np.log(predicted))\n",
    "    return loss # / float(predicted.shape[0])\n",
    "\n",
    "Y = np.array([1, 0, 0]) # one hot encoded\n",
    "Y_pred_good = np.array([0.7, 0.2, 0.1])\n",
    "Y_pred_bad = np.array([0.1, 0.3, 0.6])\n",
    "l1 = cross_entropy(Y, Y_pred_good)\n",
    "l2 = cross_entropy(Y, Y_pred_bad)\n",
    "print(f\"Loss 1 numpy: {l1:.4f}\")\n",
    "print(f\"Loss 2 numpy: {l2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e68f15f0-025b-488f-bebd-a18df05a5239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3877a5c9-9089-422a-88dd-9d1b8e0a3633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1 torch: 0.4170\n",
      "Loss 2 torch: 1.8406\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "Y = torch.tensor([0]) # not one hot encoded\n",
    "Y_pred_good = torch.tensor([[2.0, 1.0, 0.1]]) # n_samples x n_classes = 1x3; logits (softmax is applied within CrossEntropyLoss()\n",
    "Y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]])\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "print(f\"Loss 1 torch: {l1.item():.4f}\")\n",
    "print(f\"Loss 2 torch: {l2.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "295cf503-c071-4adc-a5d7-b51a2c1a8a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n",
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "_, predictions1 = torch.max(Y_pred_good, 1) # choose highest probability\n",
    "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
    "print(predictions1)\n",
    "print(predictions2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824c580e-3126-4adc-9df9-bda8b46c0a5f",
   "metadata": {},
   "source": [
    "Loss in PyTorch allows for multiple examples simultaneously!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6ffad4c9-24e7-45b3-ac7a-035935484e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1 torch: 0.3018\n",
      "Loss 2 torch: 1.6242\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "Y = torch.tensor([2, 0, 1]) # not one hot encoded\n",
    "Y_pred_good = torch.tensor([[0.1, 1.0, 2.1], [2.0, 1.0, 0.1], [0.1, 3.0, 0.1]]) # n_samples x n_classes = 3x3; logits (softmax is applied within CrossEntropyLoss()\n",
    "Y_pred_bad = torch.tensor([[2.1, 1.0, 0.1], [0.1, 1.0, 2.1], [0.1, 3.0, 0.1]])\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "print(f\"Loss 1 torch: {l1.item():.4f}\")\n",
    "print(f\"Loss 2 torch: {l2.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabd3211-15cb-434b-8572-0d2a8f9205c0",
   "metadata": {},
   "source": [
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1c26ff9f-d95d-4bcd-a706-015de2c22027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Option 1 activation functions as modules\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "    \n",
    "# option 2 activation function directly in forward pass\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.linear1(x)) # some activation functions only available in functional API, e.g. F.leaky_relu()\n",
    "        out = torch.sigmoid(self.linear2(out))\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ce461d-e9aa-4665-b8dd-dab33f8fb7cd",
   "metadata": {},
   "source": [
    "## Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2030ba01-fe80-49f8-b2e1-a20cb18d3a20",
   "metadata": {},
   "source": [
    "### Dataset & DataLoader Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8a3782b0-9b78-4368-8136-643683181e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ../datasets/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ca95eb4fee4718b1290eceb29068fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26421880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../datasets/FashionMNIST/raw/train-images-idx3-ubyte.gz to ../datasets/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ../datasets/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c81e60414a4fe198e6296f4c5a53d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../datasets/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ../datasets/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ../datasets/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5175c338a43746609543559bfd625224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4422102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../datasets/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ../datasets/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ../datasets/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05398b8226544777a1e04583ccebf208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../datasets/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ../datasets/FashionMNIST/raw\n",
      "\n",
      "Dataset Sizes: {'train': 60000, 'val': 10000}\n",
      "Class Names: ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
      "Number of Classes: 10\n",
      "Image Size: torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "# Device config (GPU support)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Datasets & DataLoaders\n",
    "datasets = {x: torchvision.datasets.FashionMNIST(root=\"../datasets\", train=(x==\"train\"),\n",
    "                                        download=True, transform=transforms.ToTensor())\n",
    "                  for x in [\"train\", \"val\"]}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=0)\n",
    "              for x in [\"train\", \"val\"]}\n",
    "\n",
    "\n",
    "dataset_sizes = {x: len(datasets[x]) for x in [\"train\", \"val\"]}\n",
    "class_names = datasets[\"train\"].classes\n",
    "n_classes = len(class_names)\n",
    "examples = iter(dataloaders[\"train\"])\n",
    "samples, labels = examples.next()\n",
    "input_size = samples.shape[2] * samples.shape[3] # 784 -> 28x28 images flattened\n",
    "print(f\"Dataset Sizes: {dataset_sizes}\")\n",
    "print(f\"Class Names: {class_names}\")\n",
    "print(f\"Number of Classes: {n_classes}\")\n",
    "print(f\"Image Size: {samples.shape[1:]}\")\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(samples[i][0], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "90bd508f-668d-4f4a-b414-e9745d75f695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop (batch training)\n",
    "def train_model(model, criterion, optimizer, n_epochs=5, greyscale_to_rgb=False):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for images, labels in dataloaders[phase]:\n",
    "                if greyscale_to_rgb == True:\n",
    "                    images = images.repeat(1, 3, 1, 1).to(device)\n",
    "                else:\n",
    "                    images = images.to(device) # push to GPU if available\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(images)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f\"{phase.capitalize() + ' Phase -> '} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == \"val\" and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f\"Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\")\n",
    "    print(f\"Best Val Acc: {best_acc:4f}\")\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "14fe72b7-45fc-403e-b353-44fb7938a5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 28*28)\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3e303f70-8fe9-46fe-a73d-8b2f3ad44db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.6862 Acc: 0.7659\n",
      "Val Phase ->  Loss: 0.5187 Acc: 0.8160\n",
      "\n",
      "Epoch 2/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.4676 Acc: 0.8374\n",
      "Val Phase ->  Loss: 0.4861 Acc: 0.8300\n",
      "\n",
      "Epoch 3/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.4271 Acc: 0.8488\n",
      "Val Phase ->  Loss: 0.4402 Acc: 0.8435\n",
      "\n",
      "Epoch 4/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3974 Acc: 0.8588\n",
      "Val Phase ->  Loss: 0.4184 Acc: 0.8494\n",
      "\n",
      "Epoch 5/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3780 Acc: 0.8659\n",
      "Val Phase ->  Loss: 0.4017 Acc: 0.8566\n",
      "\n",
      "Epoch 6/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3617 Acc: 0.8704\n",
      "Val Phase ->  Loss: 0.4221 Acc: 0.8486\n",
      "\n",
      "Epoch 7/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3496 Acc: 0.8759\n",
      "Val Phase ->  Loss: 0.3815 Acc: 0.8628\n",
      "\n",
      "Epoch 8/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3370 Acc: 0.8797\n",
      "Val Phase ->  Loss: 0.3770 Acc: 0.8654\n",
      "\n",
      "Epoch 9/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3266 Acc: 0.8827\n",
      "Val Phase ->  Loss: 0.3793 Acc: 0.8654\n",
      "\n",
      "Epoch 10/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3177 Acc: 0.8851\n",
      "Val Phase ->  Loss: 0.3930 Acc: 0.8595\n",
      "\n",
      "Epoch 11/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3111 Acc: 0.8871\n",
      "Val Phase ->  Loss: 0.3564 Acc: 0.8738\n",
      "\n",
      "Epoch 12/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3048 Acc: 0.8901\n",
      "Val Phase ->  Loss: 0.3773 Acc: 0.8620\n",
      "\n",
      "Epoch 13/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2955 Acc: 0.8922\n",
      "Val Phase ->  Loss: 0.3466 Acc: 0.8768\n",
      "\n",
      "Epoch 14/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2904 Acc: 0.8942\n",
      "Val Phase ->  Loss: 0.3470 Acc: 0.8780\n",
      "\n",
      "Epoch 15/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2863 Acc: 0.8960\n",
      "Val Phase ->  Loss: 0.3559 Acc: 0.8715\n",
      "\n",
      "Training complete in 0m 60s\n",
      "Best Val Acc: 0.878000\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "hidden_size = 100\n",
    "n_epochs = 15\n",
    "learning_rate = 0.01\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, n_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "model = train_model(model, criterion, optimizer, n_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf93db9-d28e-4f39-b12a-67b2626de5c1",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "98afdd4d-862b-4190-98dc-c7bd68cf8a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x -> n, 1, 28, 28\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 12, 12\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # -> n, 16, 4, 4\n",
    "        x = x.view(-1, 16 * 4 * 4)            # -> n, 256\n",
    "        x = F.relu(self.fc1(x))               # -> n, 120\n",
    "        x = F.relu(self.fc2(x))               # -> n, 84\n",
    "        x = self.fc3(x)                       # -> n, 10\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ccaa8831-7485-4db5-93f5-9307b5b69b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.9732 Acc: 0.6419\n",
      "Val Phase ->  Loss: 0.5966 Acc: 0.7723\n",
      "\n",
      "Epoch 2/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.5081 Acc: 0.8115\n",
      "Val Phase ->  Loss: 0.4795 Acc: 0.8199\n",
      "\n",
      "Epoch 3/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.4225 Acc: 0.8443\n",
      "Val Phase ->  Loss: 0.4467 Acc: 0.8363\n",
      "\n",
      "Epoch 4/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3797 Acc: 0.8606\n",
      "Val Phase ->  Loss: 0.3861 Acc: 0.8563\n",
      "\n",
      "Epoch 5/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3492 Acc: 0.8716\n",
      "Val Phase ->  Loss: 0.3777 Acc: 0.8636\n",
      "\n",
      "Epoch 6/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3291 Acc: 0.8781\n",
      "Val Phase ->  Loss: 0.3775 Acc: 0.8631\n",
      "\n",
      "Epoch 7/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3139 Acc: 0.8840\n",
      "Val Phase ->  Loss: 0.3522 Acc: 0.8769\n",
      "\n",
      "Epoch 8/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3008 Acc: 0.8885\n",
      "Val Phase ->  Loss: 0.3428 Acc: 0.8792\n",
      "\n",
      "Epoch 9/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2871 Acc: 0.8940\n",
      "Val Phase ->  Loss: 0.3259 Acc: 0.8824\n",
      "\n",
      "Epoch 10/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2781 Acc: 0.8966\n",
      "Val Phase ->  Loss: 0.3146 Acc: 0.8867\n",
      "\n",
      "Epoch 11/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2698 Acc: 0.9015\n",
      "Val Phase ->  Loss: 0.3202 Acc: 0.8871\n",
      "\n",
      "Epoch 12/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2591 Acc: 0.9034\n",
      "Val Phase ->  Loss: 0.3111 Acc: 0.8879\n",
      "\n",
      "Epoch 13/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2523 Acc: 0.9062\n",
      "Val Phase ->  Loss: 0.3178 Acc: 0.8858\n",
      "\n",
      "Epoch 14/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2466 Acc: 0.9085\n",
      "Val Phase ->  Loss: 0.3022 Acc: 0.8933\n",
      "\n",
      "Epoch 15/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2411 Acc: 0.9089\n",
      "Val Phase ->  Loss: 0.3009 Acc: 0.8924\n",
      "\n",
      "Training complete in 1m 21s\n",
      "Best Val Acc: 0.893300\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "n_epochs = 15\n",
    "learning_rate = 0.01\n",
    "\n",
    "model = ConvNet().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "model = train_model(model, criterion, optimizer, n_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef21d27f-2a82-4d90-bb15-c3bd780ee9f9",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe62a773-ecc1-40f9-b68d-129b22e7272f",
   "metadata": {},
   "source": [
    "What is Transfer Learning?\n",
    "- Leverage a pretrained model that has been trained on huge amounts of similar data (e.g. here ImageNet)\n",
    "- Fine-tune the model on your specific data\n",
    "- Super popular nowadays, crucial for efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ffca56c4-d234-49c4-a97e-0485ecec03fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3757 Acc: 0.8668\n",
      "Val Phase ->  Loss: 0.2717 Acc: 0.9016\n",
      "\n",
      "Epoch 2/5\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2422 Acc: 0.9108\n",
      "Val Phase ->  Loss: 0.2614 Acc: 0.9043\n",
      "\n",
      "Epoch 3/5\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2046 Acc: 0.9261\n",
      "Val Phase ->  Loss: 0.2409 Acc: 0.9132\n",
      "\n",
      "Epoch 4/5\n",
      "----------\n",
      "Train Phase ->  Loss: 0.1820 Acc: 0.9328\n",
      "Val Phase ->  Loss: 0.2394 Acc: 0.9149\n",
      "\n",
      "Epoch 5/5\n",
      "----------\n",
      "Train Phase ->  Loss: 0.1618 Acc: 0.9402\n",
      "Val Phase ->  Loss: 0.2349 Acc: 0.9216\n",
      "\n",
      "Training complete in 5m 60s\n",
      "Best Val Acc: 0.921600\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "hidden_size = 100\n",
    "n_epochs = 5\n",
    "learning_rate = 0.01\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 10)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "model = train_model(model, criterion, optimizer, n_epochs=n_epochs, greyscale_to_rgb=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
