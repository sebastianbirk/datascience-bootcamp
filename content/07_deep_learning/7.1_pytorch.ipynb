{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d33ff2fa-192a-4864-ac79-61c786d8f2cd",
   "metadata": {},
   "source": [
    "# 7.1 PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdb013a-d23a-405d-88eb-28290aecb3b1",
   "metadata": {},
   "source": [
    "This notebook is an adaptation of the PyTorch Tutorial of Patrick Loeber which you can find [here](https://github.com/python-engineer/pytorchTutorial) (MIT License - Copyright (c) 2020 Patrick Loeber)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718414fa-fd14-49d3-ae3d-97726d7ffb1f",
   "metadata": {},
   "source": [
    "What is PyTorch?\n",
    "- One of the most popular modern deep learning frameworks (next to Tensorflow, JAX)\n",
    "\n",
    "Check out this Free Online Course to learn more:\n",
    "- [Deep learning with PyTorch Free Online Course](https://www.youtube.com/watch?v=c36lUUr864M&t=8387s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ec89cfe-7d35-4097-86d8-270e75fb95f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76aada1-1092-4c4f-9ee9-9d8a281eda3f",
   "metadata": {},
   "source": [
    "Check if PyTorch can use your GPU (i.e. cuda is correctly installed and available). This is usually needed to train large-scale deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7432de24-4d80-405c-a63d-5dade646033e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd95cbd-4b58-4cc5-a813-1b83cc021a03",
   "metadata": {},
   "source": [
    "## Tensor Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56acb965-e71e-48d2-a80b-170360760802",
   "metadata": {},
   "source": [
    "Tensors are generalizations of matrices to the N-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3220b13b-31f8-4738-8b26-e03a20c35806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-1.5492e-35,  4.5911e-41,  2.7045e-43],\n",
      "          [ 0.0000e+00, -1.5315e-12,  3.0907e-41]],\n",
      "\n",
      "         [[-1.5655e-12,  3.0907e-41, -1.5488e-35],\n",
      "          [ 4.5911e-41, -1.4506e-35,  4.5911e-41]]],\n",
      "\n",
      "\n",
      "        [[[ 6.7262e-44,  0.0000e+00,  6.7262e-44],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00, -1.4506e-35],\n",
      "          [ 4.5911e-41, -3.5575e+02,  4.5909e-41]]]])\n",
      "torch.Size([2, 2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(2, 2, 2, 3)\n",
    "print(x)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e30c778-3392-4e54-9ff5-5389543b61cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8641, 0.2525, 0.0277, 0.6163, 0.0163],\n",
      "        [0.4633, 0.5661, 0.7695, 0.5905, 0.9054],\n",
      "        [0.7106, 0.2398, 0.2402, 0.5580, 0.6027]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3, 5)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aa760cc-a166-4fd6-a05d-a7605f9a843f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(2, 2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05d397cb-78fc-4719-afd9-5a41e9c4824e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d450ccd3-7280-4a90-8c1c-c2a19628bc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int32\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, dtype=torch.int)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6c8d58a-4382-459f-a555-07e2d07d410f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e3aa32d-1d8c-44eb-a54c-513e2e1cc9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.5000, 0.1000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([2.5, 0.1])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8843caa4-3fb8-4ae4-800e-5b0ef7e7e240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0293, 0.7649],\n",
      "        [0.6484, 0.3917]])\n",
      "tensor([[0.2809, 0.5074],\n",
      "        [0.3604, 0.4399]])\n",
      "tensor([[0.3101, 1.2722],\n",
      "        [1.0088, 0.8315]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 2)\n",
    "y = torch.rand(2, 2)\n",
    "z = x + y\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6e64bd0-c4de-433d-ad04-8b9d00823146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5906, 0.0910, 0.0053],\n",
      "        [0.8476, 0.0752, 0.9204],\n",
      "        [0.9489, 0.1888, 0.9422],\n",
      "        [0.5435, 0.1039, 0.1684],\n",
      "        [0.1025, 0.2719, 0.2288]])\n",
      "tensor([0.5906, 0.8476, 0.9489, 0.5435, 0.1025])\n",
      "0.07517355680465698\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "print(x[:, 0])\n",
    "print(x[1,1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36b091fb-60cc-45d3-8557-524823ba9be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6230, 0.0761, 0.5964, 0.8997],\n",
      "        [0.5664, 0.6711, 0.2935, 0.7294],\n",
      "        [0.4935, 0.5686, 0.1182, 0.0945],\n",
      "        [0.8879, 0.7853, 0.5667, 0.2213]])\n",
      "tensor([0.6230, 0.0761, 0.5964, 0.8997, 0.5664, 0.6711, 0.2935, 0.7294, 0.4935,\n",
      "        0.5686, 0.1182, 0.0945, 0.8879, 0.7853, 0.5667, 0.2213])\n",
      "tensor([[0.6230, 0.0761, 0.5964, 0.8997, 0.5664, 0.6711, 0.2935, 0.7294],\n",
      "        [0.4935, 0.5686, 0.1182, 0.0945, 0.8879, 0.7853, 0.5667, 0.2213]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4, 4)\n",
    "print(x)\n",
    "y = x.view(16)\n",
    "print(y)\n",
    "y = x.view(-1, 8)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "780c3730-2c84-48a0-9f4c-d9cc6c09e043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'numpy.ndarray'>\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(type(a))\n",
    "b = a.numpy()\n",
    "print(type(b))\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "# both objects share the same memory location when the tensor is on cpu\n",
    "a += 1\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53e703c7-4795-4159-883e-17dd75cf1758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "print(a)\n",
    "b = torch.from_numpy(a)\n",
    "print(b)\n",
    "a += 1\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43e3681c-d571-408b-8725-f163e9962b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5, requires_grad=True) # calculate gradients for this vector in the optimization step\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d7d9f1-7f76-4756-9e51-b66b315b17bd",
   "metadata": {},
   "source": [
    "## Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b442ef2-8591-442f-a6c5-cfc71e477dc1",
   "metadata": {},
   "source": [
    "Calculating gradients automatically for the optimization. PyTorch will create a computation graph for backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9448628e-6f16-4b6c-9468-04cb946eff36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0816, 0.0580, 1.6081], requires_grad=True)\n",
      "tensor([2.0816, 2.0580, 3.6081], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "print(x)\n",
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b287663-ea93-4bc9-a5a0-90a1e8e6592c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 8.6664,  8.4706, 26.0361], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = (y*y*2)\n",
    "# z = z.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ae1aa24-2a52-4109-80da-11f941f73e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.tensor([0.1, 1.0, 0.001], dtype=torch.float32)\n",
    "z.backward(v) # dz/dx -> chain rule dz/dy * dy/dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bd53c80-a475-4f8b-ba6e-ea4af585c5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8327, 8.2319, 0.0144])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "935b3e42-289b-43f2-b9d7-32b32713ae84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0816, 2.0580, 3.6081])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y = x + 2\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ca6fc08-69ff-498f-bc25-80ad334ce71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([6., 6., 6., 6.])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(4, requires_grad=True)\n",
    "\n",
    "for epoch in range(2):\n",
    "    model_output = (weights*3).sum()\n",
    "    model_output.backward()\n",
    "    print(weights.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2b416b8-39ee-4fc9-8432-b4d794327753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(4, requires_grad=True)\n",
    "\n",
    "for epoch in range(2):\n",
    "    model_output = (weights*3).sum()\n",
    "    model_output.backward()\n",
    "    print(weights.grad)\n",
    "    weights.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97686ec7-03c0-406f-9a00-5c043bad6eb6",
   "metadata": {},
   "source": [
    "## Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "546d050b-59ef-447f-84ce-2c052f8d5699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<PowBackward0>)\n",
      "tensor(-2.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)\n",
    "w = torch.tensor(1.0, requires_grad=True)\n",
    " \n",
    "# forward pass and compute loss\n",
    "y_hat = w * x\n",
    "loss = (y_hat - y)**2\n",
    "print(loss)\n",
    "\n",
    "# backward pass\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "\n",
    "# update weights\n",
    "# next forward and backward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a093fa8-2856-4cc3-86a6-f814c900b73c",
   "metadata": {},
   "source": [
    "## Gradient Descent using Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56591d4-2543-4b17-ae2f-606bd6ff282a",
   "metadata": {},
   "source": [
    "Linear Regression: Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9b0ee2f-aaac-4446-9d35-61c65aeb64e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n",
      "epoch 1: w = 0.300, loss = 30.00000000\n",
      "epoch 3: w = 0.772, loss = 15.66018677\n",
      "epoch 5: w = 1.113, loss = 8.17471600\n",
      "epoch 7: w = 1.359, loss = 4.26725292\n",
      "epoch 9: w = 1.537, loss = 2.22753215\n",
      "epoch 11: w = 1.665, loss = 1.16278565\n",
      "epoch 13: w = 1.758, loss = 0.60698175\n",
      "epoch 15: w = 1.825, loss = 0.31684822\n",
      "epoch 17: w = 1.874, loss = 0.16539653\n",
      "epoch 19: w = 1.909, loss = 0.08633806\n",
      "Prediction after training: f(5) = 9.612\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# f = w * x\n",
    "\n",
    "# f = 2 * x\n",
    "X = np.array([1, 2, 3, 4], dtype=np.float32) # feature vector\n",
    "Y = np.array([2, 4, 6, 8], dtype=np.float32) # label vector w. ground truth\n",
    "w = 0.0\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss = MSE\n",
    "def loss(y, y_predicted):\n",
    "    return ((y_predicted -y)**2).mean()\n",
    "\n",
    "# gradient\n",
    "# MSE = 1/N * (w*x-y)**2\n",
    "# dJ/dw = 1/N 2x (w*x-y)\n",
    "def gradient(x, y, y_predicted):\n",
    "    return np.dot(2 * x, y_predicted-y)/len(x)\n",
    "\n",
    "print(f\"Prediction before training: f(5) = {forward(5):.3f}\")\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    # prediction = forward pass\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradients = backward pass\n",
    "    dw = gradient(X, Y, y_pred)\n",
    "    \n",
    "    # update weights\n",
    "    w -= learning_rate * dw\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        print(f\"epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}\")\n",
    "        \n",
    "print(f\"Prediction after training: f(5) = {forward(5):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "772e51d8-cf09-4e64-9fdd-4248cbb838ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n",
      "epoch 1: w = 0.300, loss = 30.00000000\n",
      "epoch 3: w = 0.772, loss = 15.66018772\n",
      "epoch 5: w = 1.113, loss = 8.17471695\n",
      "epoch 7: w = 1.359, loss = 4.26725292\n",
      "epoch 9: w = 1.537, loss = 2.22753215\n",
      "epoch 11: w = 1.665, loss = 1.16278565\n",
      "epoch 13: w = 1.758, loss = 0.60698116\n",
      "epoch 15: w = 1.825, loss = 0.31684780\n",
      "epoch 17: w = 1.874, loss = 0.16539653\n",
      "epoch 19: w = 1.909, loss = 0.08633806\n",
      "Prediction after training: f(5) = 9.612\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# f = w * x\n",
    "\n",
    "# f = 2 * x\n",
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32) # feature vector\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32) # label vector w. ground truth\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss = MSE\n",
    "def loss(y, y_predicted):\n",
    "    return ((y_predicted -y)**2).mean()\n",
    "\n",
    "print(f\"Prediction before training: f(5) = {forward(5):.3f}\")\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    # prediction = forward pass\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradients = backward pass\n",
    "    l.backward() # dl/dw\n",
    "    \n",
    "    # update weights\n",
    "    with torch.no_grad(): # exclude from computational graph\n",
    "        w -= learning_rate * w.grad \n",
    "    \n",
    "    # zero gradients\n",
    "    w.grad.zero_()\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        print(f\"epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}\")\n",
    "        \n",
    "print(f\"Prediction after training: f(5) = {forward(5):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af832ae-0e4d-45ca-b15b-0bba54f28b6a",
   "metadata": {},
   "source": [
    "## PyTorch Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe14bf6-ad74-4978-b619-5e1be030dc47",
   "metadata": {},
   "source": [
    "1) Design model (input_size, output_size, forward pass)\n",
    "2) Construct loss and optimizer\n",
    "3) Training loop\n",
    "   - forward pass: compute prediction\n",
    "   - backward pass: compute gradients\n",
    "   - update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0cc7ed0b-af73-4966-8098-3cd4294d3326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n",
      "epoch 1: w = 0.300, loss = 30.00000000\n",
      "epoch 3: w = 0.772, loss = 15.66018772\n",
      "epoch 5: w = 1.113, loss = 8.17471695\n",
      "epoch 7: w = 1.359, loss = 4.26725292\n",
      "epoch 9: w = 1.537, loss = 2.22753215\n",
      "epoch 11: w = 1.665, loss = 1.16278565\n",
      "epoch 13: w = 1.758, loss = 0.60698116\n",
      "epoch 15: w = 1.825, loss = 0.31684780\n",
      "epoch 17: w = 1.874, loss = 0.16539653\n",
      "epoch 19: w = 1.909, loss = 0.08633806\n",
      "Prediction after training: f(5) = 9.612\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "# f = w * x\n",
    "\n",
    "# f = 2 * x\n",
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32) # feature vector\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32) # label vector w. ground truth\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss = MSE\n",
    "\n",
    "\n",
    "print(f\"Prediction before training: f(5) = {forward(5):.3f}\")\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_epochs = 20\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD([w], lr=learning_rate) # stochastic gradient descent\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # prediction = forward pass\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradients = backward pass\n",
    "    l.backward() # dl/dw\n",
    "    \n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        print(f\"epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}\")\n",
    "        \n",
    "print(f\"Prediction after training: f(5) = {forward(5):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b61efcaf-b5ec-4891-8d14-f9d10d8a8a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n",
      "Prediction before training: f(5) = -0.245\n",
      "epoch 1: w = 0.258, loss = 31.49100494\n",
      "epoch 3: w = 0.742, loss = 16.43850327\n",
      "epoch 5: w = 1.091, loss = 8.58100224\n",
      "epoch 7: w = 1.343, loss = 4.47933626\n",
      "epoch 9: w = 1.525, loss = 2.33824110\n",
      "epoch 11: w = 1.657, loss = 1.22057664\n",
      "epoch 13: w = 1.752, loss = 0.63714898\n",
      "epoch 15: w = 1.821, loss = 0.33259568\n",
      "epoch 17: w = 1.871, loss = 0.17361709\n",
      "epoch 19: w = 1.907, loss = 0.09062931\n",
      "Prediction after training: f(5) = 9.603\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "# f = w * x\n",
    "\n",
    "# f = 2 * x\n",
    "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32) # feature vector\n",
    "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32) # label vector w. ground truth\n",
    "\n",
    "X_test = torch.tensor([5], dtype=torch.float32)\n",
    "n_samples, n_features = X.shape\n",
    "print(n_samples, n_features)\n",
    "\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, bias):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        # define layers\n",
    "        self.lin = nn.Linear(input_dim, output_dim, bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "    \n",
    "model = LinearRegression(input_size, output_size, False)\n",
    "\n",
    "print(f\"Prediction before training: f(5) = {model(X_test).item():.3f}\")\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_epochs = 20\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) # stochastic gradient descent\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # prediction = forward pass\n",
    "    y_pred = model(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradients = backward pass\n",
    "    l.backward() # dl/dw\n",
    "    \n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        [w,] = model.parameters()\n",
    "        print(f\"epoch {epoch+1}: w = {w[0][0].item():.3f}, loss = {l:.8f}\")\n",
    "        \n",
    "print(f\"Prediction after training: f(5) = {model(X_test).item():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49889872-2d91-42af-9722-6c2edeaa0f23",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aec9886-b81a-4d88-aeb5-f3ed421f2ffa",
   "metadata": {},
   "source": [
    "1) Design model (input_size, output_size, forward pass)\n",
    "2) Construct loss and optimizer\n",
    "3) Training loop\n",
    "   - forward pass: compute prediction\n",
    "   - backward pass: compute gradients\n",
    "   - update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61095285-3b4e-4337-b433-9fb69d77d57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10, loss = 4432.0723\n",
      "epoch:20, loss = 3305.0249\n",
      "epoch:30, loss = 2489.7905\n",
      "epoch:40, loss = 1899.4600\n",
      "epoch:50, loss = 1471.5557\n",
      "epoch:60, loss = 1161.0978\n",
      "epoch:70, loss = 935.6567\n",
      "epoch:80, loss = 771.8208\n",
      "epoch:90, loss = 652.6686\n",
      "epoch:100, loss = 565.9550\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 0) prepare data\n",
    "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=1)\n",
    "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
    "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
    "y = y.view(y.shape[0], 1)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "# 1) model\n",
    "input_size = n_features\n",
    "output_size = 1\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "# 2) loss and optimizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 3) training loop\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # forward pass and loss\n",
    "    y_predicted = model(X)\n",
    "    loss = criterion(y_predicted, y)\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"epoch:{epoch+1}, loss = {loss.item():.4f}\")\n",
    "        \n",
    "# plot\n",
    "predicted = model(X).detach().numpy()\n",
    "plt.plot(X_numpy, y_numpy, \"ro\")\n",
    "plt.plot(X_numpy, predicted, \"b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816025f3-c171-4cb0-9514-2bfaf8152138",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88111bd6-20d4-417c-9e7d-1164917fd363",
   "metadata": {},
   "source": [
    "1) Design model (input_size, output_size, forward pass)\n",
    "2) Construct loss and optimizer\n",
    "3) Training loop\n",
    "   - forward pass: compute prediction\n",
    "   - backward pass: compute gradients\n",
    "   - update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df5829fc-3d44-453e-aff3-0d211a8aebe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569 30\n",
      "epoch 10, loss = 0.6598\n",
      "epoch 20, loss = 0.5183\n",
      "epoch 30, loss = 0.4359\n",
      "epoch 40, loss = 0.3824\n",
      "epoch 50, loss = 0.3445\n",
      "epoch 60, loss = 0.3161\n",
      "epoch 70, loss = 0.2938\n",
      "epoch 80, loss = 0.2757\n",
      "epoch 90, loss = 0.2607\n",
      "epoch 100, loss = 0.2479\n",
      "accuracy = 0.8860\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 0) prepare data\n",
    "bc = datasets.load_breast_cancer()\n",
    "X, y = bc.data, bc.target\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "print(n_samples, n_features)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "# scale\n",
    "sc = StandardScaler() # 0 mean unit variance\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)\n",
    "\n",
    "# 1) model\n",
    "# f = wx + b, sigmoid at the end\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_predicted = torch.sigmoid(self.linear(x))\n",
    "        return y_predicted\n",
    "    \n",
    "model = LogisticRegression(n_features)\n",
    "\n",
    "# 2) loss and optimizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 3) training loop\n",
    "n_epochs = 100\n",
    "for epoch in range(n_epochs):\n",
    "    # forward pass and loss\n",
    "    y_predicted = model(X_train)\n",
    "    loss = criterion(y_predicted, y_train)\n",
    "\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # updates\n",
    "    optimizer.step()\n",
    "    \n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"epoch {epoch+1}, loss = {loss.item():.4f}\")\n",
    "              \n",
    "with torch.no_grad():\n",
    "    y_predicted = model(X_test)\n",
    "    y_predicted_cls = y_predicted.round()\n",
    "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
    "    print(f\"accuracy = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc822bee-5a50-4f19-8808-f0e1f875b41d",
   "metadata": {},
   "source": [
    "## Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0fa151-dadb-4d11-bceb-07054b73b459",
   "metadata": {},
   "source": [
    "Gradient calculations on whole training dataset is very time-consuming. Better way is to divide samples in so called batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4fa41b5b-f6be-4f42-b449-671caddee64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b31213f-ecae-4707-bb31-e5a12c349096",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WineDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        # data loading\n",
    "        xy = np.loadtxt(\"../datasets/wine.csv\", delimiter=\",\", dtype=np.float32, skiprows=1)\n",
    "        self.x = torch.from_numpy(xy[:, 1:])\n",
    "        self.y = torch.from_numpy(xy[:, [0]]) # n_samples, 1\n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # dataset[0]\n",
    "        return self.x[index], self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        # len(dataset)\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dbe4eacf-1509-41eb-be84-49ec407f4055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03]) tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "dataset = WineDataset()\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67578d0b-a8ab-42fa-829e-08aefbe5e0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset=dataset, batch_size=4, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2978b5f3-a690-4437-9959-713a6f568f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2080e+01, 2.0800e+00, 1.7000e+00, 1.7500e+01, 9.7000e+01, 2.2300e+00,\n",
      "         2.1700e+00, 2.6000e-01, 1.4000e+00, 3.3000e+00, 1.2700e+00, 2.9600e+00,\n",
      "         7.1000e+02],\n",
      "        [1.2530e+01, 5.5100e+00, 2.6400e+00, 2.5000e+01, 9.6000e+01, 1.7900e+00,\n",
      "         6.0000e-01, 6.3000e-01, 1.1000e+00, 5.0000e+00, 8.2000e-01, 1.6900e+00,\n",
      "         5.1500e+02],\n",
      "        [1.2580e+01, 1.2900e+00, 2.1000e+00, 2.0000e+01, 1.0300e+02, 1.4800e+00,\n",
      "         5.8000e-01, 5.3000e-01, 1.4000e+00, 7.6000e+00, 5.8000e-01, 1.5500e+00,\n",
      "         6.4000e+02],\n",
      "        [1.4750e+01, 1.7300e+00, 2.3900e+00, 1.1400e+01, 9.1000e+01, 3.1000e+00,\n",
      "         3.6900e+00, 4.3000e-01, 2.8100e+00, 5.4000e+00, 1.2500e+00, 2.7300e+00,\n",
      "         1.1500e+03]]) tensor([[2.],\n",
      "        [3.],\n",
      "        [3.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(dataloader)\n",
    "data = dataiter.next()\n",
    "features, labels = data\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f590a3da-ac85-4645-b6a4-bc88d8d5fd7c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178 45\n",
      "epoch 1/2, step 5/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 10/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 15/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 20/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 25/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 30/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 35/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 40/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 45/45, inputs torch.Size([2, 13])\n",
      "epoch 2/2, step 5/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 10/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 15/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 20/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 25/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 30/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 35/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 40/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 45/45, inputs torch.Size([2, 13])\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "n_epochs = 2\n",
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples/4)\n",
    "print(total_samples, n_iterations)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        # forward backward, update\n",
    "        if (i+1) % 5 == 0:\n",
    "            print(f\"epoch {epoch+1}/{n_epochs}, step {i+1}/{n_iterations}, inputs {inputs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b904bb-f03d-4436-8d87-996789917a78",
   "metadata": {},
   "source": [
    "## Dataset Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d421de70-52bd-4af8-bb86-26227d23580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "69023c58-4331-46c2-bfdf-3ac8b219f8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WineDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        # data loading\n",
    "        xy = np.loadtxt(\"../datasets/wine.csv\", delimiter=\",\", dtype=np.float32, skiprows=1)\n",
    "        self.x = xy[:, 1:]\n",
    "        self.y = xy[:, [0]] # n_samples, 1\n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # dataset[0]\n",
    "        sample = self.x[index], self.y[index]\n",
    "    \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample\n",
    "        \n",
    "    def __len__(self):\n",
    "        # len(dataset)\n",
    "        return self.n_samples\n",
    "    \n",
    "    \n",
    "class ToTensor:\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
    "    \n",
    "\n",
    "class MulTransform:\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        inputs *= self.factor\n",
    "        return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02e3bb40-9c90-4ee9-b23a-47cfe6d407d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "dataset = WineDataset(transform=ToTensor())\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features)\n",
    "print(type(features), type(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "48cdb8dc-1998-4d58-a5e9-5335a1660024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.8460e+01, 3.4200e+00, 4.8600e+00, 3.1200e+01, 2.5400e+02, 5.6000e+00,\n",
      "        6.1200e+00, 5.6000e-01, 4.5800e+00, 1.1280e+01, 2.0800e+00, 7.8400e+00,\n",
      "        2.1300e+03])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(2)])\n",
    "dataset = WineDataset(transform=composed)\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features)\n",
    "print(type(features), type(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ace5ec-3f03-43ec-93fc-a6f4bf8eebeb",
   "metadata": {},
   "source": [
    "## Softmax & Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b5d9c5e2-d90b-4bde-a98d-7a4d1b367206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax numpy: [0.65900114 0.24243297 0.09856589]\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "x = np.array([2.0, 1.0, 0.1])\n",
    "outputs = softmax(x)\n",
    "print(\"Softmax numpy:\", outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "19d85185-0094-40df-a139-4f494d45008a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax torch: tensor([0.6590, 0.2424, 0.0986])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([2.0, 1.0, 0.1])\n",
    "outputs = torch.softmax(x, dim=0)\n",
    "print(\"Softmax torch:\", outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "63916baa-1b9a-416f-902d-5a2b424a5ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1 numpy: 0.3567\n",
      "Loss 2 numpy: 2.3026\n"
     ]
    }
   ],
   "source": [
    "def cross_entropy(actual, predicted):\n",
    "    loss = -np.sum(actual * np.log(predicted))\n",
    "    return loss # / float(predicted.shape[0])\n",
    "\n",
    "Y = np.array([1, 0, 0]) # one hot encoded\n",
    "Y_pred_good = np.array([0.7, 0.2, 0.1])\n",
    "Y_pred_bad = np.array([0.1, 0.3, 0.6])\n",
    "l1 = cross_entropy(Y, Y_pred_good)\n",
    "l2 = cross_entropy(Y, Y_pred_bad)\n",
    "print(f\"Loss 1 numpy: {l1:.4f}\")\n",
    "print(f\"Loss 2 numpy: {l2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e68f15f0-025b-488f-bebd-a18df05a5239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3877a5c9-9089-422a-88dd-9d1b8e0a3633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1 torch: 0.4170\n",
      "Loss 2 torch: 1.8406\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "Y = torch.tensor([0]) # not one hot encoded\n",
    "Y_pred_good = torch.tensor([[2.0, 1.0, 0.1]]) # n_samples x n_classes = 1x3; logits (softmax is applied within CrossEntropyLoss()\n",
    "Y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]])\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "print(f\"Loss 1 torch: {l1.item():.4f}\")\n",
    "print(f\"Loss 2 torch: {l2.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "295cf503-c071-4adc-a5d7-b51a2c1a8a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n",
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "_, predictions1 = torch.max(Y_pred_good, 1) # choose highest probability\n",
    "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
    "print(predictions1)\n",
    "print(predictions2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824c580e-3126-4adc-9df9-bda8b46c0a5f",
   "metadata": {},
   "source": [
    "Loss in PyTorch allows for multiple examples simultaneously!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ffad4c9-24e7-45b3-ac7a-035935484e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1 torch: 0.3018\n",
      "Loss 2 torch: 1.6242\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "Y = torch.tensor([2, 0, 1]) # not one hot encoded\n",
    "Y_pred_good = torch.tensor([[0.1, 1.0, 2.1], [2.0, 1.0, 0.1], [0.1, 3.0, 0.1]]) # n_samples x n_classes = 3x3; logits (softmax is applied within CrossEntropyLoss()\n",
    "Y_pred_bad = torch.tensor([[2.1, 1.0, 0.1], [0.1, 1.0, 2.1], [0.1, 3.0, 0.1]])\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "print(f\"Loss 1 torch: {l1.item():.4f}\")\n",
    "print(f\"Loss 2 torch: {l2.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabd3211-15cb-434b-8572-0d2a8f9205c0",
   "metadata": {},
   "source": [
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1c26ff9f-d95d-4bcd-a706-015de2c22027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Option 1 activation functions as modules\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "    \n",
    "# option 2 activation function directly in forward pass\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.linear1(x)) # some activation functions only available in functional API, e.g. F.leaky_relu()\n",
    "        out = torch.sigmoid(self.linear2(out))\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ce461d-e9aa-4665-b8dd-dab33f8fb7cd",
   "metadata": {},
   "source": [
    "## Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2030ba01-fe80-49f8-b2e1-a20cb18d3a20",
   "metadata": {},
   "source": [
    "### Dataset & DataLoader Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8a3782b0-9b78-4368-8136-643683181e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Sizes: {'train': 60000, 'val': 10000}\n",
      "Class Names: ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
      "Number of Classes: 10\n",
      "Image Size: torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "# Device config (GPU support)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Datasets & DataLoaders\n",
    "datasets = {x: torchvision.datasets.FashionMNIST(root=\"../datasets\", train=(x==\"train\"),\n",
    "                                        download=True, transform=transforms.ToTensor())\n",
    "                  for x in [\"train\", \"val\"]}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=0)\n",
    "              for x in [\"train\", \"val\"]}\n",
    "\n",
    "\n",
    "dataset_sizes = {x: len(datasets[x]) for x in [\"train\", \"val\"]}\n",
    "class_names = datasets[\"train\"].classes\n",
    "n_classes = len(class_names)\n",
    "examples = iter(dataloaders[\"train\"])\n",
    "samples, labels = examples.next()\n",
    "input_size = samples.shape[2] * samples.shape[3] # 784 -> 28x28 images flattened\n",
    "print(f\"Dataset Sizes: {dataset_sizes}\")\n",
    "print(f\"Class Names: {class_names}\")\n",
    "print(f\"Number of Classes: {n_classes}\")\n",
    "print(f\"Image Size: {samples.shape[1:]}\")\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(samples[i][0], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "90bd508f-668d-4f4a-b414-e9745d75f695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop (batch training)\n",
    "def train_model(model, criterion, optimizer, n_epochs=5, greyscale_to_rgb=False):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for images, labels in dataloaders[phase]:\n",
    "                if greyscale_to_rgb == True:\n",
    "                    images = images.repeat(1, 3, 1, 1).to(device)\n",
    "                else:\n",
    "                    images = images.to(device) # push to GPU if available\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(images)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f\"{phase.capitalize() + ' Phase -> '} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == \"val\" and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f\"Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\")\n",
    "    print(f\"Best Val Acc: {best_acc:4f}\")\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "14fe72b7-45fc-403e-b353-44fb7938a5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 28*28)\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3e303f70-8fe9-46fe-a73d-8b2f3ad44db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.6937 Acc: 0.7635\n",
      "Val Phase ->  Loss: 0.5095 Acc: 0.8217\n",
      "\n",
      "Epoch 2/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.4698 Acc: 0.8362\n",
      "Val Phase ->  Loss: 0.4678 Acc: 0.8330\n",
      "\n",
      "Epoch 3/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.4283 Acc: 0.8494\n",
      "Val Phase ->  Loss: 0.4457 Acc: 0.8422\n",
      "\n",
      "Epoch 4/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3984 Acc: 0.8594\n",
      "Val Phase ->  Loss: 0.4165 Acc: 0.8535\n",
      "\n",
      "Epoch 5/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3775 Acc: 0.8676\n",
      "Val Phase ->  Loss: 0.4121 Acc: 0.8525\n",
      "\n",
      "Epoch 6/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3627 Acc: 0.8712\n",
      "Val Phase ->  Loss: 0.4025 Acc: 0.8599\n",
      "\n",
      "Epoch 7/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3480 Acc: 0.8768\n",
      "Val Phase ->  Loss: 0.3882 Acc: 0.8632\n",
      "\n",
      "Epoch 8/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3351 Acc: 0.8811\n",
      "Val Phase ->  Loss: 0.3884 Acc: 0.8582\n",
      "\n",
      "Epoch 9/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3276 Acc: 0.8833\n",
      "Val Phase ->  Loss: 0.3754 Acc: 0.8654\n",
      "\n",
      "Epoch 10/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3175 Acc: 0.8869\n",
      "Val Phase ->  Loss: 0.3902 Acc: 0.8567\n",
      "\n",
      "Epoch 11/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3112 Acc: 0.8878\n",
      "Val Phase ->  Loss: 0.3667 Acc: 0.8712\n",
      "\n",
      "Epoch 12/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3036 Acc: 0.8908\n",
      "Val Phase ->  Loss: 0.3656 Acc: 0.8697\n",
      "\n",
      "Epoch 13/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2967 Acc: 0.8923\n",
      "Val Phase ->  Loss: 0.3683 Acc: 0.8683\n",
      "\n",
      "Epoch 14/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2887 Acc: 0.8974\n",
      "Val Phase ->  Loss: 0.3703 Acc: 0.8676\n",
      "\n",
      "Epoch 15/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2833 Acc: 0.8979\n",
      "Val Phase ->  Loss: 0.3514 Acc: 0.8752\n",
      "\n",
      "Training complete in 1m 43s\n",
      "Best Val Acc: 0.875200\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "hidden_size = 100\n",
    "n_epochs = 15\n",
    "learning_rate = 0.01\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, n_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "model = train_model(model, criterion, optimizer, n_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf93db9-d28e-4f39-b12a-67b2626de5c1",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "98afdd4d-862b-4190-98dc-c7bd68cf8a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x -> n, 1, 28, 28\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 12, 12\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # -> n, 16, 4, 4\n",
    "        x = x.view(-1, 16 * 4 * 4)            # -> n, 256\n",
    "        x = F.relu(self.fc1(x))               # -> n, 120\n",
    "        x = F.relu(self.fc2(x))               # -> n, 84\n",
    "        x = self.fc3(x)                       # -> n, 10\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ccaa8831-7485-4db5-93f5-9307b5b69b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "----------\n",
      "Train Phase ->  Loss: 1.1138 Acc: 0.5915\n",
      "Val Phase ->  Loss: 0.5907 Acc: 0.7690\n",
      "\n",
      "Epoch 2/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.5163 Acc: 0.8044\n",
      "Val Phase ->  Loss: 0.4818 Acc: 0.8262\n",
      "\n",
      "Epoch 3/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.4382 Acc: 0.8383\n",
      "Val Phase ->  Loss: 0.4108 Acc: 0.8501\n",
      "\n",
      "Epoch 4/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3873 Acc: 0.8582\n",
      "Val Phase ->  Loss: 0.3915 Acc: 0.8590\n",
      "\n",
      "Epoch 5/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3578 Acc: 0.8680\n",
      "Val Phase ->  Loss: 0.4064 Acc: 0.8545\n",
      "\n",
      "Epoch 6/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3363 Acc: 0.8749\n",
      "Val Phase ->  Loss: 0.3572 Acc: 0.8711\n",
      "\n",
      "Epoch 7/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3183 Acc: 0.8818\n",
      "Val Phase ->  Loss: 0.3496 Acc: 0.8699\n",
      "\n",
      "Epoch 8/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3064 Acc: 0.8859\n",
      "Val Phase ->  Loss: 0.3349 Acc: 0.8768\n",
      "\n",
      "Epoch 9/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2935 Acc: 0.8915\n",
      "Val Phase ->  Loss: 0.3338 Acc: 0.8784\n",
      "\n",
      "Epoch 10/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2820 Acc: 0.8949\n",
      "Val Phase ->  Loss: 0.3154 Acc: 0.8838\n",
      "\n",
      "Epoch 11/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2761 Acc: 0.8967\n",
      "Val Phase ->  Loss: 0.3256 Acc: 0.8834\n",
      "\n",
      "Epoch 12/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2644 Acc: 0.9021\n",
      "Val Phase ->  Loss: 0.3177 Acc: 0.8838\n",
      "\n",
      "Epoch 13/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2607 Acc: 0.9030\n",
      "Val Phase ->  Loss: 0.3027 Acc: 0.8894\n",
      "\n",
      "Epoch 14/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2518 Acc: 0.9066\n",
      "Val Phase ->  Loss: 0.3067 Acc: 0.8873\n",
      "\n",
      "Epoch 15/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2450 Acc: 0.9083\n",
      "Val Phase ->  Loss: 0.3201 Acc: 0.8826\n",
      "\n",
      "Training complete in 2m 20s\n",
      "Best Val Acc: 0.889400\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "n_epochs = 15\n",
    "learning_rate = 0.01\n",
    "\n",
    "model = ConvNet().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "model = train_model(model, criterion, optimizer, n_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef21d27f-2a82-4d90-bb15-c3bd780ee9f9",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe62a773-ecc1-40f9-b68d-129b22e7272f",
   "metadata": {},
   "source": [
    "What is Transfer Learning?\n",
    "- Leverage a pretrained model that has been trained on huge amounts of similar data (e.g. here ImageNet)\n",
    "- Fine-tune the model on your specific data\n",
    "- Super popular nowadays, crucial for efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ffca56c4-d234-49c4-a97e-0485ecec03fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebastianbirk/miniconda3/envs/datascience-bootcamp-7/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/sebastianbirk/miniconda3/envs/datascience-bootcamp-7/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3764 Acc: 0.8655\n",
      "Val Phase ->  Loss: 0.3099 Acc: 0.8803\n",
      "\n",
      "Epoch 2/5\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2449 Acc: 0.9109\n",
      "Val Phase ->  Loss: 0.2809 Acc: 0.8966\n",
      "\n",
      "Epoch 3/5\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2065 Acc: 0.9242\n",
      "Val Phase ->  Loss: 0.2604 Acc: 0.9076\n",
      "\n",
      "Epoch 4/5\n",
      "----------\n",
      "Train Phase ->  Loss: 0.1799 Acc: 0.9332\n",
      "Val Phase ->  Loss: 0.2355 Acc: 0.9163\n",
      "\n",
      "Epoch 5/5\n",
      "----------\n",
      "Train Phase ->  Loss: 0.1633 Acc: 0.9396\n",
      "Val Phase ->  Loss: 0.2591 Acc: 0.9078\n",
      "\n",
      "Training complete in 7m 59s\n",
      "Best Val Acc: 0.916300\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "hidden_size = 100\n",
    "n_epochs = 5\n",
    "learning_rate = 0.01\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 10)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "model = train_model(model, criterion, optimizer, n_epochs=n_epochs, greyscale_to_rgb=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
