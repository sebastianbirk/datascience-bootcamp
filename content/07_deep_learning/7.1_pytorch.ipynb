{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d33ff2fa-192a-4864-ac79-61c786d8f2cd",
   "metadata": {},
   "source": [
    "# 7.1 PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdb013a-d23a-405d-88eb-28290aecb3b1",
   "metadata": {},
   "source": [
    "This notebook is an adaptation of the PyTorch Tutorial of Patrick Loeber which you can find [here](https://github.com/python-engineer/pytorchTutorial) (MIT License - Copyright (c) 2020 Patrick Loeber)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718414fa-fd14-49d3-ae3d-97726d7ffb1f",
   "metadata": {},
   "source": [
    "What is PyTorch?\n",
    "- One of the most popular modern deep learning frameworks (next to Tensorflow, JAX)\n",
    "\n",
    "Check out this Free Online Course to learn more:\n",
    "- [Deep learning with PyTorch Free Online Course](https://www.youtube.com/watch?v=c36lUUr864M&t=8387s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ec89cfe-7d35-4097-86d8-270e75fb95f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76aada1-1092-4c4f-9ee9-9d8a281eda3f",
   "metadata": {},
   "source": [
    "Check if PyTorch can use your GPU (i.e. cuda is correctly installed and available). This is usually needed to train large-scale deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7432de24-4d80-405c-a63d-5dade646033e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd95cbd-4b58-4cc5-a813-1b83cc021a03",
   "metadata": {},
   "source": [
    "## Tensor Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56acb965-e71e-48d2-a80b-170360760802",
   "metadata": {},
   "source": [
    "Tensors are generalizations of matrices to the N-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3220b13b-31f8-4738-8b26-e03a20c35806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 2.8558e-14,  4.5783e-41,  2.7045e-43],\n",
      "          [ 0.0000e+00, -9.8273e-25,  3.0875e-41]],\n",
      "\n",
      "         [[-1.0137e-24,  3.0875e-41,  2.8549e-14],\n",
      "          [ 4.5783e-41,  2.7326e-14,  4.5783e-41]]],\n",
      "\n",
      "\n",
      "        [[[ 6.7262e-44,  0.0000e+00,  6.7262e-44],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  2.7429e-14],\n",
      "          [ 4.5783e-41,  6.7352e+23,  4.5782e-41]]]])\n",
      "torch.Size([2, 2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(2, 2, 2, 3)\n",
    "print(x)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e30c778-3392-4e54-9ff5-5389543b61cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7296, 0.8771, 0.7857, 0.3944, 0.3045],\n",
      "        [0.0997, 0.6534, 0.7018, 0.9944, 0.4723],\n",
      "        [0.7386, 0.3527, 0.4696, 0.5141, 0.5099]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3, 5)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aa760cc-a166-4fd6-a05d-a7605f9a843f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(2, 2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05d397cb-78fc-4719-afd9-5a41e9c4824e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d450ccd3-7280-4a90-8c1c-c2a19628bc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int32\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, dtype=torch.int)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6c8d58a-4382-459f-a555-07e2d07d410f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e3aa32d-1d8c-44eb-a54c-513e2e1cc9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.5000, 0.1000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([2.5, 0.1])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8843caa4-3fb8-4ae4-800e-5b0ef7e7e240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4097, 0.3577],\n",
      "        [0.1903, 0.6959]])\n",
      "tensor([[0.3297, 0.0063],\n",
      "        [0.2855, 0.6194]])\n",
      "tensor([[0.7394, 0.3640],\n",
      "        [0.4758, 1.3153]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 2)\n",
    "y = torch.rand(2, 2)\n",
    "z = x + y\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6e64bd0-c4de-433d-ad04-8b9d00823146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6895, 0.9338, 0.6797],\n",
      "        [0.6076, 0.1237, 0.2892],\n",
      "        [0.1989, 0.2350, 0.5699],\n",
      "        [0.4852, 0.5110, 0.8027],\n",
      "        [0.6303, 0.3685, 0.1028]])\n",
      "tensor([0.6895, 0.6076, 0.1989, 0.4852, 0.6303])\n",
      "0.12369048595428467\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "print(x[:, 0])\n",
    "print(x[1,1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36b091fb-60cc-45d3-8557-524823ba9be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5467, 0.5482, 0.2149, 0.1953],\n",
      "        [0.7832, 0.5489, 0.3489, 0.1300],\n",
      "        [0.7268, 0.9470, 0.4963, 0.1456],\n",
      "        [0.5821, 0.7757, 0.8802, 0.8277]])\n",
      "tensor([0.5467, 0.5482, 0.2149, 0.1953, 0.7832, 0.5489, 0.3489, 0.1300, 0.7268,\n",
      "        0.9470, 0.4963, 0.1456, 0.5821, 0.7757, 0.8802, 0.8277])\n",
      "tensor([[0.5467, 0.5482, 0.2149, 0.1953, 0.7832, 0.5489, 0.3489, 0.1300],\n",
      "        [0.7268, 0.9470, 0.4963, 0.1456, 0.5821, 0.7757, 0.8802, 0.8277]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4, 4)\n",
    "print(x)\n",
    "y = x.view(16)\n",
    "print(y)\n",
    "y = x.view(-1, 8)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "780c3730-2c84-48a0-9f4c-d9cc6c09e043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'numpy.ndarray'>\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(type(a))\n",
    "b = a.numpy()\n",
    "print(type(b))\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "# both objects share the same memory location when the tensor is on cpu\n",
    "a += 1\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53e703c7-4795-4159-883e-17dd75cf1758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "print(a)\n",
    "b = torch.from_numpy(a)\n",
    "print(b)\n",
    "a += 1\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43e3681c-d571-408b-8725-f163e9962b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5, requires_grad=True) # calculate gradients for this vector in the optimization step\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d7d9f1-7f76-4756-9e51-b66b315b17bd",
   "metadata": {},
   "source": [
    "## Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b442ef2-8591-442f-a6c5-cfc71e477dc1",
   "metadata": {},
   "source": [
    "Calculating gradients automatically for the optimization. PyTorch will create a computation graph for backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9448628e-6f16-4b6c-9468-04cb946eff36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4714, -0.9677,  0.7668], requires_grad=True)\n",
      "tensor([1.5286, 1.0323, 2.7668], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "print(x)\n",
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b287663-ea93-4bc9-a5a0-90a1e8e6592c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4.6733,  2.1314, 15.3100], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = (y*y*2)\n",
    "# z = z.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ae1aa24-2a52-4109-80da-11f941f73e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.tensor([0.1, 1.0, 0.001], dtype=torch.float32)\n",
    "z.backward(v) # dz/dx -> chain rule dz/dy * dy/dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bd53c80-a475-4f8b-ba6e-ea4af585c5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6114, 4.1293, 0.0111])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "935b3e42-289b-43f2-b9d7-32b32713ae84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.5286, 1.0323, 2.7668])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y = x + 2\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ca6fc08-69ff-498f-bc25-80ad334ce71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([6., 6., 6., 6.])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(4, requires_grad=True)\n",
    "\n",
    "for epoch in range(2):\n",
    "    model_output = (weights*3).sum()\n",
    "    model_output.backward()\n",
    "    print(weights.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2b416b8-39ee-4fc9-8432-b4d794327753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(4, requires_grad=True)\n",
    "\n",
    "for epoch in range(2):\n",
    "    model_output = (weights*3).sum()\n",
    "    model_output.backward()\n",
    "    print(weights.grad)\n",
    "    weights.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97686ec7-03c0-406f-9a00-5c043bad6eb6",
   "metadata": {},
   "source": [
    "## Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "546d050b-59ef-447f-84ce-2c052f8d5699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<PowBackward0>)\n",
      "tensor(-2.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)\n",
    "w = torch.tensor(1.0, requires_grad=True)\n",
    " \n",
    "# forward pass and compute loss\n",
    "y_hat = w * x\n",
    "loss = (y_hat - y)**2\n",
    "print(loss)\n",
    "\n",
    "# backward pass\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "\n",
    "# update weights\n",
    "# next forward and backward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a093fa8-2856-4cc3-86a6-f814c900b73c",
   "metadata": {},
   "source": [
    "## Gradient Descent using Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56591d4-2543-4b17-ae2f-606bd6ff282a",
   "metadata": {},
   "source": [
    "Linear Regression: Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9b0ee2f-aaac-4446-9d35-61c65aeb64e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n",
      "epoch 1: w = 0.300, loss = 30.00000000\n",
      "epoch 3: w = 0.772, loss = 15.66018677\n",
      "epoch 5: w = 1.113, loss = 8.17471600\n",
      "epoch 7: w = 1.359, loss = 4.26725292\n",
      "epoch 9: w = 1.537, loss = 2.22753215\n",
      "epoch 11: w = 1.665, loss = 1.16278565\n",
      "epoch 13: w = 1.758, loss = 0.60698175\n",
      "epoch 15: w = 1.825, loss = 0.31684822\n",
      "epoch 17: w = 1.874, loss = 0.16539653\n",
      "epoch 19: w = 1.909, loss = 0.08633806\n",
      "Prediction after training: f(5) = 9.612\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# f = w * x\n",
    "\n",
    "# f = 2 * x\n",
    "X = np.array([1, 2, 3, 4], dtype=np.float32) # feature vector\n",
    "Y = np.array([2, 4, 6, 8], dtype=np.float32) # label vector w. ground truth\n",
    "w = 0.0\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss = MSE\n",
    "def loss(y, y_predicted):\n",
    "    return ((y_predicted -y)**2).mean()\n",
    "\n",
    "# gradient\n",
    "# MSE = 1/N * (w*x-y)**2\n",
    "# dJ/dw = 1/N 2x (w*x-y)\n",
    "def gradient(x, y, y_predicted):\n",
    "    return np.dot(2 * x, y_predicted-y)/len(x)\n",
    "\n",
    "print(f\"Prediction before training: f(5) = {forward(5):.3f}\")\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    # prediction = forward pass\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradients = backward pass\n",
    "    dw = gradient(X, Y, y_pred)\n",
    "    \n",
    "    # update weights\n",
    "    w -= learning_rate * dw\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        print(f\"epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}\")\n",
    "        \n",
    "print(f\"Prediction after training: f(5) = {forward(5):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "772e51d8-cf09-4e64-9fdd-4248cbb838ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n",
      "epoch 1: w = 0.300, loss = 30.00000000\n",
      "epoch 3: w = 0.772, loss = 15.66018772\n",
      "epoch 5: w = 1.113, loss = 8.17471695\n",
      "epoch 7: w = 1.359, loss = 4.26725292\n",
      "epoch 9: w = 1.537, loss = 2.22753215\n",
      "epoch 11: w = 1.665, loss = 1.16278565\n",
      "epoch 13: w = 1.758, loss = 0.60698116\n",
      "epoch 15: w = 1.825, loss = 0.31684780\n",
      "epoch 17: w = 1.874, loss = 0.16539653\n",
      "epoch 19: w = 1.909, loss = 0.08633806\n",
      "Prediction after training: f(5) = 9.612\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# f = w * x\n",
    "\n",
    "# f = 2 * x\n",
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32) # feature vector\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32) # label vector w. ground truth\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss = MSE\n",
    "def loss(y, y_predicted):\n",
    "    return ((y_predicted -y)**2).mean()\n",
    "\n",
    "print(f\"Prediction before training: f(5) = {forward(5):.3f}\")\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    # prediction = forward pass\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradients = backward pass\n",
    "    l.backward() # dl/dw\n",
    "    \n",
    "    # update weights\n",
    "    with torch.no_grad(): # exclude from computational graph\n",
    "        w -= learning_rate * w.grad \n",
    "    \n",
    "    # zero gradients\n",
    "    w.grad.zero_()\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        print(f\"epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}\")\n",
    "        \n",
    "print(f\"Prediction after training: f(5) = {forward(5):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af832ae-0e4d-45ca-b15b-0bba54f28b6a",
   "metadata": {},
   "source": [
    "## PyTorch Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe14bf6-ad74-4978-b619-5e1be030dc47",
   "metadata": {},
   "source": [
    "1) Design model (input_size, output_size, forward pass)\n",
    "2) Construct loss and optimizer\n",
    "3) Training loop\n",
    "   - forward pass: compute prediction\n",
    "   - backward pass: compute gradients\n",
    "   - update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0cc7ed0b-af73-4966-8098-3cd4294d3326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n",
      "epoch 1: w = 0.300, loss = 30.00000000\n",
      "epoch 3: w = 0.772, loss = 15.66018772\n",
      "epoch 5: w = 1.113, loss = 8.17471695\n",
      "epoch 7: w = 1.359, loss = 4.26725292\n",
      "epoch 9: w = 1.537, loss = 2.22753215\n",
      "epoch 11: w = 1.665, loss = 1.16278565\n",
      "epoch 13: w = 1.758, loss = 0.60698116\n",
      "epoch 15: w = 1.825, loss = 0.31684780\n",
      "epoch 17: w = 1.874, loss = 0.16539653\n",
      "epoch 19: w = 1.909, loss = 0.08633806\n",
      "Prediction after training: f(5) = 9.612\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "# f = w * x\n",
    "\n",
    "# f = 2 * x\n",
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32) # feature vector\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32) # label vector w. ground truth\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss = MSE\n",
    "\n",
    "\n",
    "print(f\"Prediction before training: f(5) = {forward(5):.3f}\")\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_epochs = 20\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD([w], lr=learning_rate) # stochastic gradient descent\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # prediction = forward pass\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradients = backward pass\n",
    "    l.backward() # dl/dw\n",
    "    \n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        print(f\"epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}\")\n",
    "        \n",
    "print(f\"Prediction after training: f(5) = {forward(5):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b61efcaf-b5ec-4891-8d14-f9d10d8a8a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n",
      "Prediction before training: f(5) = 4.861\n",
      "epoch 1: w = 1.126, loss = 7.92402315\n",
      "epoch 3: w = 1.369, loss = 4.13638973\n",
      "epoch 5: w = 1.544, loss = 2.15922141\n",
      "epoch 7: w = 1.670, loss = 1.12712717\n",
      "epoch 9: w = 1.762, loss = 0.58836746\n",
      "epoch 11: w = 1.828, loss = 0.30713132\n",
      "epoch 13: w = 1.876, loss = 0.16032438\n",
      "epoch 15: w = 1.910, loss = 0.08369037\n",
      "epoch 17: w = 1.935, loss = 0.04368686\n",
      "epoch 19: w = 1.953, loss = 0.02280485\n",
      "Prediction after training: f(5) = 9.801\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "# f = w * x\n",
    "\n",
    "# f = 2 * x\n",
    "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32) # feature vector\n",
    "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32) # label vector w. ground truth\n",
    "\n",
    "X_test = torch.tensor([5], dtype=torch.float32)\n",
    "n_samples, n_features = X.shape\n",
    "print(n_samples, n_features)\n",
    "\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, bias):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        # define layers\n",
    "        self.lin = nn.Linear(input_dim, output_dim, bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "    \n",
    "model = LinearRegression(input_size, output_size, False)\n",
    "\n",
    "print(f\"Prediction before training: f(5) = {model(X_test).item():.3f}\")\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_epochs = 20\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) # stochastic gradient descent\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # prediction = forward pass\n",
    "    y_pred = model(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradients = backward pass\n",
    "    l.backward() # dl/dw\n",
    "    \n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        [w,] = model.parameters()\n",
    "        print(f\"epoch {epoch+1}: w = {w[0][0].item():.3f}, loss = {l:.8f}\")\n",
    "        \n",
    "print(f\"Prediction after training: f(5) = {model(X_test).item():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49889872-2d91-42af-9722-6c2edeaa0f23",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aec9886-b81a-4d88-aeb5-f3ed421f2ffa",
   "metadata": {},
   "source": [
    "1) Design model (input_size, output_size, forward pass)\n",
    "2) Construct loss and optimizer\n",
    "3) Training loop\n",
    "   - forward pass: compute prediction\n",
    "   - backward pass: compute gradients\n",
    "   - update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61095285-3b4e-4337-b433-9fb69d77d57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10, loss = 4438.0674\n",
      "epoch:20, loss = 3310.2754\n",
      "epoch:30, loss = 2494.2073\n",
      "epoch:40, loss = 1903.0739\n",
      "epoch:50, loss = 1474.4543\n",
      "epoch:60, loss = 1163.3877\n",
      "epoch:70, loss = 937.4448\n",
      "epoch:80, loss = 773.2043\n",
      "epoch:90, loss = 653.7308\n",
      "epoch:100, loss = 566.7659\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 0) prepare data\n",
    "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=1)\n",
    "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
    "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
    "y = y.view(y.shape[0], 1)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "# 1) model\n",
    "input_size = n_features\n",
    "output_size = 1\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "# 2) loss and optimizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 3) training loop\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # forward pass and loss\n",
    "    y_predicted = model(X)\n",
    "    loss = criterion(y_predicted, y)\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"epoch:{epoch+1}, loss = {loss.item():.4f}\")\n",
    "        \n",
    "# plot\n",
    "predicted = model(X).detach().numpy()\n",
    "plt.plot(X_numpy, y_numpy, \"ro\")\n",
    "plt.plot(X_numpy, predicted, \"b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816025f3-c171-4cb0-9514-2bfaf8152138",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88111bd6-20d4-417c-9e7d-1164917fd363",
   "metadata": {},
   "source": [
    "1) Design model (input_size, output_size, forward pass)\n",
    "2) Construct loss and optimizer\n",
    "3) Training loop\n",
    "   - forward pass: compute prediction\n",
    "   - backward pass: compute gradients\n",
    "   - update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df5829fc-3d44-453e-aff3-0d211a8aebe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569 30\n",
      "epoch 10, loss = 0.4071\n",
      "epoch 20, loss = 0.3617\n",
      "epoch 30, loss = 0.3288\n",
      "epoch 40, loss = 0.3036\n",
      "epoch 50, loss = 0.2836\n",
      "epoch 60, loss = 0.2672\n",
      "epoch 70, loss = 0.2535\n",
      "epoch 80, loss = 0.2418\n",
      "epoch 90, loss = 0.2316\n",
      "epoch 100, loss = 0.2227\n",
      "accuracy = 0.9035\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 0) prepare data\n",
    "bc = datasets.load_breast_cancer()\n",
    "X, y = bc.data, bc.target\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "print(n_samples, n_features)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "# scale\n",
    "sc = StandardScaler() # 0 mean unit variance\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)\n",
    "\n",
    "# 1) model\n",
    "# f = wx + b, sigmoid at the end\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_predicted = torch.sigmoid(self.linear(x))\n",
    "        return y_predicted\n",
    "    \n",
    "model = LogisticRegression(n_features)\n",
    "\n",
    "# 2) loss and optimizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 3) training loop\n",
    "n_epochs = 100\n",
    "for epoch in range(n_epochs):\n",
    "    # forward pass and loss\n",
    "    y_predicted = model(X_train)\n",
    "    loss = criterion(y_predicted, y_train)\n",
    "\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # updates\n",
    "    optimizer.step()\n",
    "    \n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"epoch {epoch+1}, loss = {loss.item():.4f}\")\n",
    "              \n",
    "with torch.no_grad():\n",
    "    y_predicted = model(X_test)\n",
    "    y_predicted_cls = y_predicted.round()\n",
    "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
    "    print(f\"accuracy = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc822bee-5a50-4f19-8808-f0e1f875b41d",
   "metadata": {},
   "source": [
    "## Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0fa151-dadb-4d11-bceb-07054b73b459",
   "metadata": {},
   "source": [
    "Gradient calculations on whole training dataset is very time-consuming. Better way is to divide samples in so called batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4fa41b5b-f6be-4f42-b449-671caddee64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b31213f-ecae-4707-bb31-e5a12c349096",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WineDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        # data loading\n",
    "        xy = np.loadtxt(\"../datasets/wine.csv\", delimiter=\",\", dtype=np.float32, skiprows=1)\n",
    "        self.x = torch.from_numpy(xy[:, 1:])\n",
    "        self.y = torch.from_numpy(xy[:, [0]]) # n_samples, 1\n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # dataset[0]\n",
    "        return self.x[index], self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        # len(dataset)\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dbe4eacf-1509-41eb-be84-49ec407f4055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03]) tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "dataset = WineDataset()\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67578d0b-a8ab-42fa-829e-08aefbe5e0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset=dataset, batch_size=4, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2978b5f3-a690-4437-9959-713a6f568f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2930e+01, 3.8000e+00, 2.6500e+00, 1.8600e+01, 1.0200e+02, 2.4100e+00,\n",
      "         2.4100e+00, 2.5000e-01, 1.9800e+00, 4.5000e+00, 1.0300e+00, 3.5200e+00,\n",
      "         7.7000e+02],\n",
      "        [1.3270e+01, 4.2800e+00, 2.2600e+00, 2.0000e+01, 1.2000e+02, 1.5900e+00,\n",
      "         6.9000e-01, 4.3000e-01, 1.3500e+00, 1.0200e+01, 5.9000e-01, 1.5600e+00,\n",
      "         8.3500e+02],\n",
      "        [1.2370e+01, 1.1700e+00, 1.9200e+00, 1.9600e+01, 7.8000e+01, 2.1100e+00,\n",
      "         2.0000e+00, 2.7000e-01, 1.0400e+00, 4.6800e+00, 1.1200e+00, 3.4800e+00,\n",
      "         5.1000e+02],\n",
      "        [1.2370e+01, 1.6300e+00, 2.3000e+00, 2.4500e+01, 8.8000e+01, 2.2200e+00,\n",
      "         2.4500e+00, 4.0000e-01, 1.9000e+00, 2.1200e+00, 8.9000e-01, 2.7800e+00,\n",
      "         3.4200e+02]]) tensor([[1.],\n",
      "        [3.],\n",
      "        [2.],\n",
      "        [2.]])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(dataloader)\n",
    "data = dataiter.next()\n",
    "features, labels = data\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f590a3da-ac85-4645-b6a4-bc88d8d5fd7c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178 45\n",
      "epoch 1/2, step 5/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 10/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 15/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 20/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 25/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 30/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 35/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 40/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 45/45, inputs torch.Size([2, 13])\n",
      "epoch 2/2, step 5/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 10/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 15/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 20/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 25/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 30/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 35/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 40/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 45/45, inputs torch.Size([2, 13])\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "n_epochs = 2\n",
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples/4)\n",
    "print(total_samples, n_iterations)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        # forward backward, update\n",
    "        if (i+1) % 5 == 0:\n",
    "            print(f\"epoch {epoch+1}/{n_epochs}, step {i+1}/{n_iterations}, inputs {inputs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b904bb-f03d-4436-8d87-996789917a78",
   "metadata": {},
   "source": [
    "## Dataset Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d421de70-52bd-4af8-bb86-26227d23580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "69023c58-4331-46c2-bfdf-3ac8b219f8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WineDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        # data loading\n",
    "        xy = np.loadtxt(\"../datasets/wine.csv\", delimiter=\",\", dtype=np.float32, skiprows=1)\n",
    "        self.x = xy[:, 1:]\n",
    "        self.y = xy[:, [0]] # n_samples, 1\n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # dataset[0]\n",
    "        sample = self.x[index], self.y[index]\n",
    "    \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample\n",
    "        \n",
    "    def __len__(self):\n",
    "        # len(dataset)\n",
    "        return self.n_samples\n",
    "    \n",
    "    \n",
    "class ToTensor:\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
    "    \n",
    "\n",
    "class MulTransform:\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        inputs *= self.factor\n",
    "        return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02e3bb40-9c90-4ee9-b23a-47cfe6d407d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "dataset = WineDataset(transform=ToTensor())\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features)\n",
    "print(type(features), type(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "48cdb8dc-1998-4d58-a5e9-5335a1660024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.8460e+01, 3.4200e+00, 4.8600e+00, 3.1200e+01, 2.5400e+02, 5.6000e+00,\n",
      "        6.1200e+00, 5.6000e-01, 4.5800e+00, 1.1280e+01, 2.0800e+00, 7.8400e+00,\n",
      "        2.1300e+03])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(2)])\n",
    "dataset = WineDataset(transform=composed)\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features)\n",
    "print(type(features), type(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ace5ec-3f03-43ec-93fc-a6f4bf8eebeb",
   "metadata": {},
   "source": [
    "## Softmax & Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b5d9c5e2-d90b-4bde-a98d-7a4d1b367206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax numpy: [0.65900114 0.24243297 0.09856589]\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "x = np.array([2.0, 1.0, 0.1])\n",
    "outputs = softmax(x)\n",
    "print(\"Softmax numpy:\", outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "19d85185-0094-40df-a139-4f494d45008a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax torch: tensor([0.6590, 0.2424, 0.0986])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([2.0, 1.0, 0.1])\n",
    "outputs = torch.softmax(x, dim=0)\n",
    "print(\"Softmax torch:\", outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "63916baa-1b9a-416f-902d-5a2b424a5ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1 numpy: 0.3567\n",
      "Loss 2 numpy: 2.3026\n"
     ]
    }
   ],
   "source": [
    "def cross_entropy(actual, predicted):\n",
    "    loss = -np.sum(actual * np.log(predicted))\n",
    "    return loss # / float(predicted.shape[0])\n",
    "\n",
    "Y = np.array([1, 0, 0]) # one hot encoded\n",
    "Y_pred_good = np.array([0.7, 0.2, 0.1])\n",
    "Y_pred_bad = np.array([0.1, 0.3, 0.6])\n",
    "l1 = cross_entropy(Y, Y_pred_good)\n",
    "l2 = cross_entropy(Y, Y_pred_bad)\n",
    "print(f\"Loss 1 numpy: {l1:.4f}\")\n",
    "print(f\"Loss 2 numpy: {l2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e68f15f0-025b-488f-bebd-a18df05a5239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3877a5c9-9089-422a-88dd-9d1b8e0a3633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1 torch: 0.4170\n",
      "Loss 2 torch: 1.8406\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "Y = torch.tensor([0]) # not one hot encoded\n",
    "Y_pred_good = torch.tensor([[2.0, 1.0, 0.1]]) # n_samples x n_classes = 1x3; logits (softmax is applied within CrossEntropyLoss()\n",
    "Y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]])\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "print(f\"Loss 1 torch: {l1.item():.4f}\")\n",
    "print(f\"Loss 2 torch: {l2.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "295cf503-c071-4adc-a5d7-b51a2c1a8a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n",
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "_, predictions1 = torch.max(Y_pred_good, 1) # choose highest probability\n",
    "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
    "print(predictions1)\n",
    "print(predictions2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824c580e-3126-4adc-9df9-bda8b46c0a5f",
   "metadata": {},
   "source": [
    "Loss in PyTorch allows for multiple examples simultaneously!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ffad4c9-24e7-45b3-ac7a-035935484e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1 torch: 0.3018\n",
      "Loss 2 torch: 1.6242\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "Y = torch.tensor([2, 0, 1]) # not one hot encoded\n",
    "Y_pred_good = torch.tensor([[0.1, 1.0, 2.1], [2.0, 1.0, 0.1], [0.1, 3.0, 0.1]]) # n_samples x n_classes = 3x3; logits (softmax is applied within CrossEntropyLoss()\n",
    "Y_pred_bad = torch.tensor([[2.1, 1.0, 0.1], [0.1, 1.0, 2.1], [0.1, 3.0, 0.1]])\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "print(f\"Loss 1 torch: {l1.item():.4f}\")\n",
    "print(f\"Loss 2 torch: {l2.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabd3211-15cb-434b-8572-0d2a8f9205c0",
   "metadata": {},
   "source": [
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1c26ff9f-d95d-4bcd-a706-015de2c22027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Option 1 activation functions as modules\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "    \n",
    "# option 2 activation function directly in forward pass\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.linear1(x)) # some activation functions only available in functional API, e.g. F.leaky_relu()\n",
    "        out = torch.sigmoid(self.linear2(out))\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ce461d-e9aa-4665-b8dd-dab33f8fb7cd",
   "metadata": {},
   "source": [
    "## Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2030ba01-fe80-49f8-b2e1-a20cb18d3a20",
   "metadata": {},
   "source": [
    "### Dataset & DataLoader Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8a3782b0-9b78-4368-8136-643683181e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Sizes: {'train': 60000, 'val': 10000}\n",
      "Class Names: ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
      "Number of Classes: 10\n",
      "Image Size: torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "# Device config (GPU support)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Datasets & DataLoaders\n",
    "datasets = {x: torchvision.datasets.FashionMNIST(root=\"../datasets\", train=(x==\"train\"),\n",
    "                                        download=True, transform=transforms.ToTensor())\n",
    "                  for x in [\"train\", \"val\"]}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=0)\n",
    "              for x in [\"train\", \"val\"]}\n",
    "\n",
    "\n",
    "dataset_sizes = {x: len(datasets[x]) for x in [\"train\", \"val\"]}\n",
    "class_names = datasets[\"train\"].classes\n",
    "n_classes = len(class_names)\n",
    "examples = iter(dataloaders[\"train\"])\n",
    "samples, labels = examples.next()\n",
    "input_size = samples.shape[2] * samples.shape[3] # 784 -> 28x28 images flattened\n",
    "print(f\"Dataset Sizes: {dataset_sizes}\")\n",
    "print(f\"Class Names: {class_names}\")\n",
    "print(f\"Number of Classes: {n_classes}\")\n",
    "print(f\"Image Size: {samples.shape[1:]}\")\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(samples[i][0], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "90bd508f-668d-4f4a-b414-e9745d75f695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop (batch training)\n",
    "def train_model(model, criterion, optimizer, n_epochs=5, greyscale_to_rgb=False):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for images, labels in dataloaders[phase]:\n",
    "                if greyscale_to_rgb == True:\n",
    "                    images = images.repeat(1, 3, 1, 1).to(device)\n",
    "                else:\n",
    "                    images = images.to(device) # push to GPU if available\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(images)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f\"{phase.capitalize() + ' Phase -> '} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == \"val\" and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f\"Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\")\n",
    "    print(f\"Best Val Acc: {best_acc:4f}\")\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "14fe72b7-45fc-403e-b353-44fb7938a5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 28*28)\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3e303f70-8fe9-46fe-a73d-8b2f3ad44db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.7008 Acc: 0.7601\n",
      "Val Phase ->  Loss: 0.5083 Acc: 0.8221\n",
      "\n",
      "Epoch 2/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.4684 Acc: 0.8362\n",
      "Val Phase ->  Loss: 0.4732 Acc: 0.8322\n",
      "\n",
      "Epoch 3/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.4295 Acc: 0.8492\n",
      "Val Phase ->  Loss: 0.4550 Acc: 0.8371\n",
      "\n",
      "Epoch 4/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3998 Acc: 0.8581\n",
      "Val Phase ->  Loss: 0.4253 Acc: 0.8480\n",
      "\n",
      "Epoch 5/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3780 Acc: 0.8660\n",
      "Val Phase ->  Loss: 0.4091 Acc: 0.8545\n",
      "\n",
      "Epoch 6/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3628 Acc: 0.8707\n",
      "Val Phase ->  Loss: 0.3963 Acc: 0.8578\n",
      "\n",
      "Epoch 7/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3525 Acc: 0.8744\n",
      "Val Phase ->  Loss: 0.3872 Acc: 0.8625\n",
      "\n",
      "Epoch 8/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3410 Acc: 0.8772\n",
      "Val Phase ->  Loss: 0.3937 Acc: 0.8614\n",
      "\n",
      "Epoch 9/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3294 Acc: 0.8815\n",
      "Val Phase ->  Loss: 0.3750 Acc: 0.8670\n",
      "\n",
      "Epoch 10/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3219 Acc: 0.8835\n",
      "Val Phase ->  Loss: 0.3922 Acc: 0.8613\n",
      "\n",
      "Epoch 11/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3126 Acc: 0.8870\n",
      "Val Phase ->  Loss: 0.3598 Acc: 0.8721\n",
      "\n",
      "Epoch 12/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3064 Acc: 0.8891\n",
      "Val Phase ->  Loss: 0.3724 Acc: 0.8648\n",
      "\n",
      "Epoch 13/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2993 Acc: 0.8918\n",
      "Val Phase ->  Loss: 0.3505 Acc: 0.8738\n",
      "\n",
      "Epoch 14/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2910 Acc: 0.8952\n",
      "Val Phase ->  Loss: 0.3549 Acc: 0.8730\n",
      "\n",
      "Epoch 15/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2872 Acc: 0.8954\n",
      "Val Phase ->  Loss: 0.3567 Acc: 0.8723\n",
      "\n",
      "Training complete in 1m 9s\n",
      "Best Val Acc: 0.873800\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "hidden_size = 100\n",
    "n_epochs = 15\n",
    "learning_rate = 0.01\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, n_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "model = train_model(model, criterion, optimizer, n_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf93db9-d28e-4f39-b12a-67b2626de5c1",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "98afdd4d-862b-4190-98dc-c7bd68cf8a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x -> n, 1, 28, 28\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 12, 12\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # -> n, 16, 4, 4\n",
    "        x = x.view(-1, 16 * 4 * 4)            # -> n, 256\n",
    "        x = F.relu(self.fc1(x))               # -> n, 120\n",
    "        x = F.relu(self.fc2(x))               # -> n, 84\n",
    "        x = self.fc3(x)                       # -> n, 10\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ccaa8831-7485-4db5-93f5-9307b5b69b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "----------\n",
      "Train Phase ->  Loss: 1.0176 Acc: 0.6097\n",
      "Val Phase ->  Loss: 0.6141 Acc: 0.7725\n",
      "\n",
      "Epoch 2/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.5232 Acc: 0.8038\n",
      "Val Phase ->  Loss: 0.4936 Acc: 0.8191\n",
      "\n",
      "Epoch 3/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.4395 Acc: 0.8400\n",
      "Val Phase ->  Loss: 0.4328 Acc: 0.8433\n",
      "\n",
      "Epoch 4/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3939 Acc: 0.8569\n",
      "Val Phase ->  Loss: 0.4105 Acc: 0.8510\n",
      "\n",
      "Epoch 5/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3627 Acc: 0.8666\n",
      "Val Phase ->  Loss: 0.3659 Acc: 0.8664\n",
      "\n",
      "Epoch 6/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3425 Acc: 0.8740\n",
      "Val Phase ->  Loss: 0.3656 Acc: 0.8709\n",
      "\n",
      "Epoch 7/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3252 Acc: 0.8802\n",
      "Val Phase ->  Loss: 0.3526 Acc: 0.8721\n",
      "\n",
      "Epoch 8/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3108 Acc: 0.8847\n",
      "Val Phase ->  Loss: 0.3383 Acc: 0.8784\n",
      "\n",
      "Epoch 9/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3004 Acc: 0.8888\n",
      "Val Phase ->  Loss: 0.3459 Acc: 0.8778\n",
      "\n",
      "Epoch 10/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2894 Acc: 0.8939\n",
      "Val Phase ->  Loss: 0.3310 Acc: 0.8801\n",
      "\n",
      "Epoch 11/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2804 Acc: 0.8964\n",
      "Val Phase ->  Loss: 0.3249 Acc: 0.8832\n",
      "\n",
      "Epoch 12/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2720 Acc: 0.8992\n",
      "Val Phase ->  Loss: 0.3224 Acc: 0.8849\n",
      "\n",
      "Epoch 13/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2631 Acc: 0.9020\n",
      "Val Phase ->  Loss: 0.3135 Acc: 0.8882\n",
      "\n",
      "Epoch 14/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2559 Acc: 0.9056\n",
      "Val Phase ->  Loss: 0.3372 Acc: 0.8762\n",
      "\n",
      "Epoch 15/15\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2491 Acc: 0.9080\n",
      "Val Phase ->  Loss: 0.3156 Acc: 0.8908\n",
      "\n",
      "Training complete in 1m 37s\n",
      "Best Val Acc: 0.890800\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "n_epochs = 15\n",
    "learning_rate = 0.01\n",
    "\n",
    "model = ConvNet().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "model = train_model(model, criterion, optimizer, n_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef21d27f-2a82-4d90-bb15-c3bd780ee9f9",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe62a773-ecc1-40f9-b68d-129b22e7272f",
   "metadata": {},
   "source": [
    "What is Transfer Learning?\n",
    "- Leverage a pretrained model that has been trained on huge amounts of similar data (e.g. here ImageNet)\n",
    "- Fine-tune the model on your specific data\n",
    "- Super popular nowadays, crucial for efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ffca56c4-d234-49c4-a97e-0485ecec03fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neslihankeskin/miniconda3/envs/datascience-bootcamp-7/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/neslihankeskin/miniconda3/envs/datascience-bootcamp-7/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /home/neslihankeskin/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3e435bdac17475bb68faf8d98568324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "----------\n",
      "Train Phase ->  Loss: 0.3725 Acc: 0.8685\n",
      "Val Phase ->  Loss: 0.2862 Acc: 0.9012\n",
      "\n",
      "Epoch 2/5\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2417 Acc: 0.9125\n",
      "Val Phase ->  Loss: 0.2716 Acc: 0.8990\n",
      "\n",
      "Epoch 3/5\n",
      "----------\n",
      "Train Phase ->  Loss: 0.2037 Acc: 0.9255\n",
      "Val Phase ->  Loss: 0.2255 Acc: 0.9178\n",
      "\n",
      "Epoch 4/5\n",
      "----------\n",
      "Train Phase ->  Loss: 0.1782 Acc: 0.9343\n",
      "Val Phase ->  Loss: 0.2409 Acc: 0.9099\n",
      "\n",
      "Epoch 5/5\n",
      "----------\n",
      "Train Phase ->  Loss: 0.1605 Acc: 0.9408\n",
      "Val Phase ->  Loss: 0.2533 Acc: 0.9161\n",
      "\n",
      "Training complete in 6m 20s\n",
      "Best Val Acc: 0.917800\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "hidden_size = 100\n",
    "n_epochs = 5\n",
    "learning_rate = 0.01\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 10)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "model = train_model(model, criterion, optimizer, n_epochs=n_epochs, greyscale_to_rgb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d198f13-c639-455c-ba0c-b08581dd50b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
