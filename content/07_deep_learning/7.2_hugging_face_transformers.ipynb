{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44647800-52d9-4bdd-b749-d74fe1e1b5ad",
   "metadata": {},
   "source": [
    "# 7.2 Hugging Face Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bc46e9-1caa-4e2c-87a1-e00e780d1846",
   "metadata": {},
   "source": [
    "In this lab session, we will have a look at [Hugging Face Transformers](https://huggingface.co/). Hugging Face is a community and data science platform that provides tools that enable users to build, train and deploy ML models based on open source code and technologies. Hugging Face started off as a platform specific to the domain of natural language processing (NLP) but has been extended to other domains such as computer vision, audio, tabular, multimodal and reinforcement learning in the meantime. Most notably, Hugging Face offers a variety of large-scale pretrained (transformer) models that you can download and finetune on your own datasets, a concept called transfer learning that has taken the deep learning field by storm.\n",
    "\n",
    "The Hugging Face ecosystem consists of:\n",
    "- A hub for models and datasets\n",
    "- Open source libraries that facilitate the development, training and deployment of ML models, especially leveraging the state-of-the-art transformers architecture:\n",
    "    - Transformers\n",
    "    - Datasets\n",
    "    - Tokenizers\n",
    "    - Accelerate\n",
    "\n",
    "To learn more about the Hugging Face ecosystem, check the [Hugging Face course](https://huggingface.co/course/chapter1/1). This notebook is heavily based on this course.\n",
    "If you want to have a look at the models that are available through Hugging Face, check the [Hugging Face hub](https://huggingface.co/models)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bba3de5-b561-42fd-834f-82950815cced",
   "metadata": {},
   "source": [
    "**What is NLP?**\n",
    "\n",
    "NLP is a field of linguistics and machine learning focused on understanding everything related to human language. The aim of NLP tasks is not only to understand single words individually, but to be able to understand the context of those words.\n",
    "\n",
    "The following is a list of common NLP tasks, with some examples of each:\n",
    "\n",
    "- Classifying whole sentences: Getting the sentiment of a review, detecting if an email is spam, determining if a sentence is grammatically correct or whether two sentences are logically related or not\n",
    "- Classifying each word in a sentence: Identifying the grammatical components of a sentence (noun, verb, adjective), or the named entities (person, location, organization)\n",
    "- Generating text content: Completing a prompt with auto-generated text, filling in the blanks in a text with masked words\n",
    "- Extracting an answer from a text: Given a question and a context, extracting the answer to the question based on the information provided in the context\n",
    "- Generating a new sentence from an input text: Translating a text into another language, summarizing a text\n",
    "\n",
    "NLP isn‚Äôt limited to written text though. It also tackles complex challenges in speech recognition and computer vision, such as generating a transcript of an audio sample or a description of an image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfac5624-6b89-4913-b466-05c452825bfc",
   "metadata": {},
   "source": [
    "**Transformers**\n",
    "\n",
    "Transformers are the state-of-the-art deep learning architecture for sequence (and image) tasks. If you are curious about the transformer architecture and how it works under the hood, make sure to check out the Hugging Face course linked at the top of the notebook.\n",
    "\n",
    "Reading the paper that originally proposed the transformer architecture called \"Attention Is All You Need\" is a must do for everyone who wants to dive into modern deep learning. It can be found [here](https://arxiv.org/abs/1706.03762). Below is an overview diagram of the model architecture:\n",
    "\n",
    "![transformer_architecture](images/transformer_architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc6875b-9710-4c2b-8206-f5e7d91ae58e",
   "metadata": {},
   "source": [
    "### 7.2.1 Transformers Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8283e07e-9d06-46d0-aa60-6e60300373fb",
   "metadata": {},
   "source": [
    "The goal of the ü§ó Transformers is to provide a single API through which any Transformer model can be loaded, trained, and saved. The library‚Äôs main features are:\n",
    "\n",
    "Ease of use: Downloading, loading, and using a state-of-the-art NLP model for inference can be done in just two lines of code.\n",
    "Flexibility: At their core, all models are simple PyTorch nn.Module or TensorFlow tf.keras.Model classes and can be handled like any other models in their respective machine learning (ML) frameworks.\n",
    "Simplicity: Hardly any abstractions are made across the library. The ‚ÄúAll in one file‚Äù is a core concept: a model‚Äôs forward pass is entirely defined in a single file, so that the code itself is understandable and hackable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6540fe60-2992-4fd7-b921-2af7aac1ad9e",
   "metadata": {},
   "source": [
    "The most basic object in the ü§ó Transformers library is the pipeline() function. It connects a model with its necessary preprocessing and postprocessing steps, allowing us to directly input any text and get an intelligible answer.\n",
    "\n",
    "Some of the currently available pipelines are:\n",
    "\n",
    "- feature-extraction (get the vector representation of a text)\n",
    "- fill-mask\n",
    "- ner (named entity recognition)\n",
    "- question-answering\n",
    "- sentiment-analysis\n",
    "- summarization\n",
    "- text-generation\n",
    "- translation\n",
    "- zero-shot-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2419aa2e-1b58-4a69-95aa-30a4eeca59eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2912a51-d254-4ded-b5ee-f8793af226a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6997af4fd19349b69892c9803d8670f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e5c910628c4926a78a3272d1b44cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/255M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68fc69ad640c455ab706a7fd27bf062b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8eff31fe924dd9b228af1994ca0e32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"I've been waiting for a HuggingFace course my whole life.\")\n",
    "# By default, this pipeline selects a particular pretrained model that has been fine-tuned for sentiment analysis in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b77bf6f4-6a50-4617-987e-3e438130e92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6653f1b1065347c6bf4861da4b0def03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.13k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0f7be0be3a24e35853964138a7f22eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f7ec1bac52b488b8fb72068c356c956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dab121e2ab3441ba2e2bbe4c5fe4c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44b8d10638d4b6fbcd0d1eccc8213dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "887a82b0430741bbbd706f26cce7c899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a course about the Transformers library',\n",
       " 'labels': ['education', 'business', 'politics'],\n",
       " 'scores': [0.8445994853973389, 0.11197376996278763, 0.043426763266325]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "classifier(\n",
    "    \"This is a course about the Transformers library\",\n",
    "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5f1059-7e64-4967-a507-28d5500de059",
   "metadata": {},
   "source": [
    "Let's search for a particular model on the [model hub](https://huggingface.co/models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa5df686-75dd-44fc-84b9-e3e4955ef0a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b7a24ac461441492442043a578eb0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ca2a6a822845f4ad68e1aa95511590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/336M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "220a519919d247b293b5475ff3275b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ccc8648a5e04b14baf2e11fe0554987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9481846952422cbf02e6434c1a6766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to build an app for Android using the open source code, using the open source SDK. After these resources'},\n",
       " {'generated_text': 'In this course, we will teach you how to use Python 2.2 and 3 to configure all the virtual machines for the Virtual Machine (VM).'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
    "generator(\n",
    "    \"In this course, we will teach you how to\",\n",
    "    max_length=30,\n",
    "    num_return_sequences=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae7f85f7-b0a3-49e0-ac96-81da1b11632b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFind a text generation model for another language and try it out!\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TO DO ###\n",
    "'''\n",
    "Find a text generation model for another language and try it out!\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "908fe76e-57ba-436d-9ec0-9d97c67f9cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08fbcf09fe9f4a62a6b4994ad47ff595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/998 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a54d72fcba6e4155a251446ba31443ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e9276a4c4b4528a60f9a6a14ad6f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c426ae1e9ef4a7b89b63c1b7643a439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebastianbirk/miniconda3/envs/datascience-bootcamp-7/lib/python3.9/site-packages/transformers/pipelines/token_classification.py:135: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.999059,\n",
       "  'word': 'Sebastian',\n",
       "  'start': 11,\n",
       "  'end': 20},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9967142,\n",
       "  'word': 'Avanade',\n",
       "  'start': 35,\n",
       "  'end': 42},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9960038,\n",
       "  'word': 'Munich',\n",
       "  'start': 46,\n",
       "  'end': 52}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "ner(\"My name is Sebastian and I work at Avanade in Munich.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccb0ed56-be31-41f3-b613-cacfae13a4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf1ea3e1aab4fc9812287b4fa97e31a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bdc750f88124dc282a079b2ce2e1d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/249M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c73d83e85d294255802d2e6a1ed97fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a19db9e05a654bbf91f0b674d52c72a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "309a35f56198447d8269f044d2ac907c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/426k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.43235573172569275,\n",
       " 'start': 35,\n",
       " 'end': 52,\n",
       " 'answer': 'Avanade in Munich'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answerer = pipeline(\"question-answering\")\n",
    "question_answerer(\n",
    "    question=\"Where do I work?\",\n",
    "    context=\"My name is Sebastian and I work at Avanade in Munich.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f01f4db8-0941-4aef-8a59-3ee54f3a2d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9d9ffc4c3e64e0c9fec33518f7e61c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.76k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbc3c028ebb743d2933dd9656e072282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.14G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d20728564ed84f3f810f83f3ed830b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd4af4e09224a17a9ea37c315202902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bdabd89da934776aaff667ce6eb68d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' America has changed dramatically during recent years . The number of engineering graduates in the U.S. has declined in traditional engineering disciplines such as mechanical, civil,    electrical, chemical, and aeronautical engineering . Rapidly developing economies such as China and India continue to encourage and advance the teaching of engineering .'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")\n",
    "summarizer(\n",
    "    \"\"\"\n",
    "    America has changed dramatically during recent years. Not only has the number of \n",
    "    graduates in traditional engineering disciplines such as mechanical, civil, \n",
    "    electrical, chemical, and aeronautical engineering declined, but in most of \n",
    "    the premier American universities engineering curricula now concentrate on \n",
    "    and encourage largely the study of engineering science. As a result, there \n",
    "    are declining offerings in engineering subjects dealing with infrastructure, \n",
    "    the environment, and related issues, and greater concentration on high \n",
    "    technology subjects, largely supporting increasingly complex scientific \n",
    "    developments. While the latter is important, it should not be at the expense \n",
    "    of more traditional engineering.\n",
    "\n",
    "    Rapidly developing economies such as China and India, as well as other \n",
    "    industrial countries in Europe and Asia, continue to encourage and advance \n",
    "    the teaching of engineering. Both China and India, respectively, graduate \n",
    "    six and eight times as many traditional engineers as does the United States. \n",
    "    Other industrial countries at minimum maintain their output, while America \n",
    "    suffers an increasingly serious decline in the number of engineering graduates \n",
    "    and a lack of well-educated engineers.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0721eadd-2ce5-4401-b25c-16843d364a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14974de22f524087ad1c2326b7fc78ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.26k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b72fb8e11943f7988a8bab10dd2d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/287M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb172b5751a45ab8fbb7b00a6753589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a437dea2a82a4e8586e376cf6039fb6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading source.spm:   0%|          | 0.00/784k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8516df5df11f49469554f481bca9f982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading target.spm:   0%|          | 0.00/760k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a1f29f346d44489dbc75dad4aa9872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/1.28M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebastianbirk/miniconda3/envs/datascience-bootcamp-7/lib/python3.9/site-packages/transformers/models/marian/tokenization_marian.py:198: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'This datascience bootcamp course is produced by Avanade.'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
    "translator(\"Ce datascience bootcamp cours est produit par Avanade.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34a8574-c239-470e-8faf-b438f77aefcc",
   "metadata": {},
   "source": [
    "This is a short history summary of transformer models. Depending on the architecture and tasks they were trained on, the performance is different for different tasks at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceec0c6-8d52-4e44-97d6-b504a4789b3d",
   "metadata": {},
   "source": [
    "![transformers_history](images/transformers_history.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e842a60b-6432-4318-8150-b54e74fa29da",
   "metadata": {},
   "source": [
    "All the Transformer models mentioned above (GPT, BERT, BART, T5, etc.) have been trained as language models. This means they have been trained on large amounts of raw text in a self-supervised fashion. Self-supervised learning is a type of training in which the objective is automatically computed from the inputs of the model. That means that humans are not needed to label the data!\n",
    "\n",
    "This type of model develops a statistical understanding of the language it has been trained on, but it‚Äôs not very useful for specific practical tasks. Because of this, the general pretrained model then goes through a process called transfer learning. During this process, the model is fine-tuned in a supervised way ‚Äî that is, using human-annotated labels ‚Äî on a given task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2a72e5-4d2d-4065-a882-d2480b6d8f3d",
   "metadata": {},
   "source": [
    "An example of a task is predicting the next word in a sentence having read the n previous words. This is called causal language modeling because the output depends on the past and present inputs, but not the future ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeae3ca-6867-4fb3-8497-6c821454917f",
   "metadata": {},
   "source": [
    "![causal_language_modeling](images/causal_language_modeling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380bc140-b65f-425f-9267-68cabbdf0280",
   "metadata": {},
   "source": [
    "Another example is masked language modeling, in which the model predicts a masked word in the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f6f804-72b4-4767-8e98-540ff3611e23",
   "metadata": {},
   "source": [
    "![masked_language_modeling](images/masked_language_modeling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad58e96-d52d-4ed2-8f59-a3dc1eff4efb",
   "metadata": {},
   "source": [
    "Apart from a few outliers (like DistilBERT), the general strategy to achieve better performance is by increasing the models‚Äô sizes as well as the amount of data they are pretrained on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f6ca78-96d1-4fcf-bfbc-c8e58a062180",
   "metadata": {},
   "source": [
    "![transformers_numbersofparams](images/transformers_numberofparams.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7139634c-c255-42a0-a4c2-d75a2bcf8196",
   "metadata": {},
   "source": [
    "[Transfer learning](https://www.youtube.com/watch?v=BqqfQnyjmgg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496ac6bf-550a-4e84-a6e3-e9e062705d3d",
   "metadata": {},
   "source": [
    "Pretraining is the act of training a model from scratch: the weights are randomly initialized, and the training starts without any prior knowledge. This pretraining is usually done on very large amounts of data. Therefore, it requires a very large corpus of data, and training can take up to several weeks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2b28cb-4e98-453d-95ca-f1784c0d8886",
   "metadata": {},
   "source": [
    "![pretraining](images/pretraining.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181fb987-7261-424f-8045-0c499e2095d6",
   "metadata": {},
   "source": [
    "Fine-tuning, on the other hand, is the training done after a model has been pretrained. To perform fine-tuning, you first acquire a pretrained language model, then perform additional training with a dataset specific to your task. Wait ‚Äî why not simply train directly for the final task? There are a couple of reasons:\n",
    "\n",
    "The pretrained model was already trained on a dataset that has some similarities with the fine-tuning dataset. The fine-tuning process is thus able to take advantage of knowledge acquired by the initial model during pretraining (for instance, with NLP problems, the pretrained model will have some kind of statistical understanding of the language you are using for your task).\n",
    "Since the pretrained model was already trained on lots of data, the fine-tuning requires way less data to get decent results.\n",
    "For the same reason, the amount of time and resources needed to get good results are much lower.\n",
    "For example, one could leverage a pretrained model trained on the English language and then fine-tune it on an arXiv corpus, resulting in a science/research-based model. The fine-tuning will only require a limited amount of data: the knowledge the pretrained model has acquired is ‚Äútransferred,‚Äù hence the term transfer learning.\n",
    "\n",
    "The fine-tuning of a language model is cheaper than pretraining in both time and money.\n",
    "Fine-tuning a model therefore has lower time, data, financial, and environmental costs. It is also quicker and easier to iterate over different fine-tuning schemes, as the training is less constraining than a full pretraining.\n",
    "\n",
    "This process will also achieve better results than training from scratch (unless you have lots of data), which is why you should always try to leverage a pretrained model ‚Äî one as close as possible to the task you have at hand ‚Äî and fine-tune it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f48e240-0ff7-4807-bd0f-72aa12a4ebda",
   "metadata": {},
   "source": [
    "![finetuning](images/finetuning.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
