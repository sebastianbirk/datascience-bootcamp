# 5. Supervised Machine Learning

### 5.1 **Overview**

Supervised learning algorithms model the relationship between features (independent variables) and a label (target) given a set of observation. Then the model is used to predict the label of new observations using the features.
This session will introduce you to supervised machine learning, guiding you through the implementation and nuances of many popular machine learning algorithms while facilitating a deep understanding along the way.

Depending on the characteristics of target variable, it can be a classification (discrete target variable) or a regression (continuous target variable) task.

![image](https://user-images.githubusercontent.com/37260563/182246657-9e7d5f9b-2f38-48b0-a300-22881bd69ac6.png)


### 5.2 **What you will learn**
  - Discover how a machine can learn a concept and generalize its understanding to new data
  - Use the Scikit-Learn library to deploy ready-built models, train them, and see results in just a few lines of code
  - Implement several well-known supervised learning algorithms from scratch - both for Regression and Classification
  - Evaluate your models to ensure they can be trusted! 
  - Use cross validation and hyper-parameter optimization to get the best possible version of each model for your specific application.


### 5.3 **Prerequisites**
This session assumes familiarity with Jupyter Lab and basics of pandas, matplotlib and numpy.
</br > The libraries Pandas, Scikit-learn, Xgboost and MatplotLib must be installed.

### 5.4 **Getting started**
To get your environment set up, make sure you have Conda installed and on your path. Then simply run the following:

- To enter the directory: **cd datascience-bootcamp**
- To extract recent files from github: **git pull**
- To activate your environment in a Unix environment:  **conda activate datascience-bootcamp**
- To launch Jupyter Lab: **jupyter lab --no-browser**

### 5.5  Link to Data & Notebooks:

- *Lecture Notebooks -*<br>

  Day 1 (Regression & Classification basics) - https://github.com/sebastianbirk/datascience-bootcamp/blob/main/content/05_supervised_machine_learning/Day_1_Lecture%20Notes.ipynb <br>
  Day 2 (Ensemble Models  & Hyperparameter tuning) - https://github.com/sebastianbirk/datascience-bootcamp/blob/main/content/05_supervised_machine_learning/Day_2_Lecture%20Notes.ipynb  

- *Datasets:* <br>

  Regression - https://github.com/sebastianbirk/datascience-bootcamp/tree/main/content/datasets/regression/processed <br>
  Classification - https://github.com/sebastianbirk/datascience-bootcamp/tree/main/content/datasets/classification/processed

- *Feature Engineered / PreProcessed solution (Part1) from where datasets are considered from* - <br>

  Regression - https://github.com/sebastianbirk/datascience-bootcamp/blob/main/content/04_data_preprocessing_%26_feature_engineering/Regression_dataset_preprocessing.ipynb <br>
  Classification - https://github.com/sebastianbirk/datascience-bootcamp/blob/main/content/04_data_preprocessing_%26_feature_engineering/Solution_Classification_preprocessing.ipynb

- *LAB Notebooks* - <br>

  Regression - https://github.com/sebastianbirk/datascience-bootcamp/blob/main/content/05_supervised_machine_learning/LAB_Regression_Day1_%26_Day2.ipynb <br>
  Classification - https://github.com/sebastianbirk/datascience-bootcamp/blob/main/content/05_supervised_machine_learning/LAB_Classification_Day1%20%26%20Day2.ipynb

