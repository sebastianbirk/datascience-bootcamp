{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9zjdtGdHnND"
   },
   "source": [
    "# **Cross Validation & Hyperparameter Tuning** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1** - Feature Engineering --> ../content/04_data_preprocessing_&_feature_engineering/Solution_Classification_preprocessing.ipynb\n",
    "\n",
    "**Part 2** - Model Building & Evaluation --> ../content/05_supervised_machine_learning/Classification_Part2_Model building & Evaluation.ipynb\n",
    "\n",
    "\n",
    "This notebook contains Hyperparameter Tuning of Various Machine Learning algorithms and comparision of their performances.\n",
    "\n",
    "**Input Data:** Cleaned and pre-processed files from Feature engineering session are used as input.\n",
    "\n",
    "    x_train.csv, x_test.csv, y_train.csv, y_test.csv\n",
    "    Location --> ../content/04_data_preprocessing_&_feature_engineering/Solution_Classification_preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dByMsuzT8Tnw"
   },
   "outputs": [],
   "source": [
    "#importing required libraries for data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Visuals and Time libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Import tuning library from sklearn\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "#Import Data balancing libraries\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Import evaluation metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20659, 19) (8984, 19) (20659, 1) (8984, 1)\n"
     ]
    }
   ],
   "source": [
    "# Read the training & test datasets from Part1- Feature Engineering solution \n",
    "\n",
    "x_train=pd.read_csv('../datasets/classification/processed/X_train.csv', index_col=0)\n",
    "x_test=pd.read_csv('../datasets/classification/processed/X_test.csv', index_col=0)\n",
    "\n",
    "y_train=pd.read_csv('../datasets/classification/processed/y_train.csv', index_col=0)\n",
    "y_test=pd.read_csv('../datasets/classification/processed/y_test.csv', index_col=0)\n",
    "\n",
    "print(x_train.shape,x_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing SMOTETomek to handle class imbalance\n",
    "\n",
    "balanced_data = SMOTETomek(random_state=42)\n",
    "\n",
    "# fit predictor and target variable\n",
    "x_smote, y_smote = balanced_data.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To fix DataConversionWarning\n",
    "y_smote = y_smote.values.ravel()\n",
    "y_test = y_test.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross-Validation:\n",
    "    \n",
    "    The Cross-Validation then iterates through the folds and at each iteration uses one of the K folds as the validation set while using all remaining folds as the training set. This process is repeated until every fold has been used as a validation set. \n",
    "    K fold --> CV = x   where x Indicates number of iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter Tuning with Grid search\n",
    "\n",
    "With this technique, we simply build a model for each possible combination of all of the hyperparameter values provided, evaluating each model, and selecting the architecture which produces the best results.\n",
    "\n",
    "Hyperparameter --> parameter whose value is used to control the learning process\n",
    "\n",
    "* Each ML model has its own set of hyperparameters\n",
    "* Tree based models share few hyperparamaters considering their similar learning process\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93y49U1mNisy",
    "tags": []
   },
   "source": [
    "### 1. **Logistic Regression Model**\n",
    "\n",
    "\n",
    "Possible parameters to tune:\n",
    "\n",
    "    1. Regularization - penalty in [‘none’, ‘l1’, ‘l2’, ‘elasticnet’]\n",
    "    2. The C parameter controls the penality strength - C in [100, 10, 1.0, 0.1, 0.01, 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zP2dZF0ONqAs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "# Identifying Grid Hyperparameters to train Logistic regression model\n",
    "param_distributions = {'penalty': ['l1','l2', 'elasticnet'],\n",
    "              'C' : [0.001, 0.1, 0.5, 0.75, 1, 10]}\n",
    "\n",
    "start = time.time()\n",
    "logi = LogisticRegression(max_iter=400)\n",
    "\n",
    "logi_grid = RandomizedSearchCV(logi,param_distributions, n_jobs=-1, random_state=0, cv=5, verbose=1)\n",
    "logi_grid.fit(x_smote,y_smote)\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.1, max_iter=400)\n",
      "{'penalty': 'l2', 'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Displaying best parameters\n",
    "print(logi_grid.best_estimator_)\n",
    "print(logi_grid.best_params_)\n",
    "\n",
    "logi_optimal_model = logi_grid.best_estimator_\n",
    "\n",
    "#class prediction of y on train and test\n",
    "y_pred_logi_grid = logi_optimal_model.predict(x_test)\n",
    "y_train_pred_logi_grid = logi_optimal_model.predict(x_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zk_nJEJkRLlr",
    "outputId": "ea0e6664-ea7c-49bd-8b77-8144bffc91de"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC</th>\n",
       "      <th>Training Time(s)</th>\n",
       "      <th>Important Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression tuned</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.801523</td>\n",
       "      <td>[AGE_median, PAY_0, PAY_2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Train Accuracy  Test Accuracy  Precision  \\\n",
       "0  Logistic Regression tuned           0.632          0.557      0.738   \n",
       "\n",
       "   Recall  F1 Score    ROC  Training Time(s)          Important Features  \n",
       "0   0.299     0.426  0.585          5.801523  [AGE_median, PAY_0, PAY_2]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting all scores for Logistic Regression\n",
    "log_acctr = round(accuracy_score(y_train_pred_logi_grid,y_smote), 3)\n",
    "log_acc = round(accuracy_score(y_pred_logi_grid,y_test), 3)\n",
    "log_prec = round(precision_score(y_pred_logi_grid,y_test), 3)\n",
    "log_rec = round(recall_score(y_pred_logi_grid,y_test), 3)\n",
    "log_f1 = round(f1_score(y_pred_logi_grid,y_test), 3)\n",
    "log_roc = round(roc_auc_score(y_pred_logi_grid,y_test), 3)\n",
    "\n",
    "#Feature co-efficients (Coef_ - Is generally not a great representaion of feature importance)\n",
    "ft_imp = pd.DataFrame(data={'Attribute': x_smote.columns,'Importance': logi_optimal_model.coef_[0]}).sort_values(by='Importance', ascending=False)\n",
    "log_feat = np.array(ft_imp['Attribute'][:3:])\n",
    "\n",
    "#Training time calculation\n",
    "log_time=stop-start\n",
    "\n",
    "results = pd.DataFrame([['Logistic Regression tuned', log_acctr, log_acc, log_prec, log_rec, log_f1, log_roc, log_time, log_feat]],\n",
    "               columns = ['Model', 'Train Accuracy', 'Test Accuracy', 'Precision', 'Recall', 'F1 Score','ROC', 'Training Time(s)','Important Features'])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93y49U1mNisy",
    "tags": []
   },
   "source": [
    "### 2. **KNN Model**\n",
    "\n",
    "Possible parameters to tune:\n",
    "\n",
    "    1. n_neighbors - Number of neighbors\n",
    "    2. leaf_size = list(range(1,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "zP2dZF0ONqAs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "# Identifying Grid Hyperparameters to train Logistic regression model\n",
    "param_distributions = {'leaf_size': list(range(1,50)),\n",
    "              'n_neighbors' : list(range(1,30))}\n",
    "\n",
    "start = time.time()\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn_grid = RandomizedSearchCV(knn, param_distributions, n_jobs=-1, random_state=0, cv=5, verbose=1)\n",
    "knn_grid.fit(x_smote,y_smote)\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(leaf_size=20, n_neighbors=9)\n",
      "{'n_neighbors': 9, 'leaf_size': 20}\n"
     ]
    }
   ],
   "source": [
    "# Displaying best parameters\n",
    "print(knn_grid.best_estimator_)\n",
    "print(knn_grid.best_params_)\n",
    "\n",
    "knn_optimal_model = knn_grid.best_estimator_\n",
    "\n",
    "#class prediction of y on train and test\n",
    "y_pred_knn_grid = knn_optimal_model.predict(x_test)\n",
    "y_train_pred_knn_grid = knn_optimal_model.predict(x_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zk_nJEJkRLlr",
    "outputId": "ea0e6664-ea7c-49bd-8b77-8144bffc91de"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC</th>\n",
       "      <th>Training Time(s)</th>\n",
       "      <th>Important Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K Nearest Neighbor tuned</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.564</td>\n",
       "      <td>9.038884</td>\n",
       "      <td>[No coefficients available]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  Train Accuracy  Test Accuracy  Precision  Recall  \\\n",
       "0  K Nearest Neighbor tuned           0.798          0.624      0.521   0.301   \n",
       "\n",
       "   F1 Score    ROC  Training Time(s)           Important Features  \n",
       "0     0.382  0.564          9.038884  [No coefficients available]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting all scores for Logistic Regression\n",
    "knn_acctr = round(accuracy_score(y_train_pred_knn_grid,y_smote), 3)\n",
    "knn_acc = round(accuracy_score(y_pred_knn_grid,y_test), 3)\n",
    "knn_prec = round(precision_score(y_pred_knn_grid,y_test), 3)\n",
    "knn_rec = round(recall_score(y_pred_knn_grid,y_test), 3)\n",
    "knn_f1 = round(f1_score(y_pred_knn_grid,y_test), 3)\n",
    "knn_roc = round(roc_auc_score(y_pred_knn_grid,y_test), 3)\n",
    "\n",
    "#Feature Importance\n",
    "knn_feat = ['No coefficients available']\n",
    "\n",
    "#Training time calculation\n",
    "knn_time=stop-start\n",
    "\n",
    "results = pd.DataFrame([['K Nearest Neighbor tuned', knn_acctr, knn_acc, knn_prec, knn_rec, knn_f1, knn_roc, knn_time, knn_feat]],\n",
    "               columns = ['Model', 'Train Accuracy', 'Test Accuracy', 'Precision', 'Recall', 'F1 Score','ROC', 'Training Time(s)','Important Features'])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. **Decision Trees**\n",
    "\n",
    "Possible parameters to tune:\n",
    "\n",
    "    1. max_depth\n",
    "    2. min_samples_split\n",
    "    3. min_samples_leaf\n",
    "    4. max_features\n",
    "    5. max_leaf_nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "usq4TOmoT534"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "# Identifying Grid Hyperparameters to train the model\n",
    "param_distributions = {'max_depth': [5, 10, 30, 50],\n",
    "#              'min_samples_split': [2, 5, 10, 15],\n",
    "              'min_samples_leaf': [2, 5, 10, 20],\n",
    "               'max_features' : [2, 5, 10, 30]}\n",
    "\n",
    "start = time.time()\n",
    "# Create an instance of the decision tree\n",
    "dtc = DecisionTreeClassifier()\n",
    "\n",
    "# Grid search\n",
    "dtc_grid = RandomizedSearchCV(dtc, param_distributions, n_jobs=-1, random_state=0, cv=5, verbose=1)\n",
    "dtc_grid.fit(x_smote, y_smote)\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ZcjDMtTMT539"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=10, max_features=30, min_samples_leaf=5)\n",
      "{'min_samples_leaf': 5, 'max_features': 30, 'max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "# Displaying best parameters\n",
    "print(dtc_grid.best_estimator_)\n",
    "print(dtc_grid.best_params_)\n",
    "\n",
    "dtc_optimal_model = dtc_grid.best_estimator_\n",
    "\n",
    "# class prediction of y on train and test\n",
    "y_pred_dtc_grid=dtc_optimal_model.predict(x_test)\n",
    "y_train_pred_dtc_grid=dtc_optimal_model.predict(x_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8984,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC</th>\n",
       "      <th>Training Time(s)</th>\n",
       "      <th>Important Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision trees tuned</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.704</td>\n",
       "      <td>2.244369</td>\n",
       "      <td>[PAY_0, MARRIAGE_married, SEX_female]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Train Accuracy  Test Accuracy  Precision  Recall  \\\n",
       "0  Decision trees tuned            0.87          0.798      0.394   0.567   \n",
       "\n",
       "   F1 Score    ROC  Training Time(s)                     Important Features  \n",
       "0     0.465  0.704          2.244369  [PAY_0, MARRIAGE_married, SEX_female]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting all scores for Decision trees\n",
    "dtc_acctr = round(accuracy_score(y_train_pred_dtc_grid,y_smote), 3)\n",
    "dtc_acc = round(accuracy_score(y_pred_dtc_grid,y_test), 3)\n",
    "dtc_prec = round(precision_score(y_pred_dtc_grid,y_test), 3)\n",
    "dtc_rec = round(recall_score(y_pred_dtc_grid,y_test), 3)\n",
    "dtc_f1 = round(f1_score(y_pred_dtc_grid,y_test), 3)\n",
    "dtc_roc = round(roc_auc_score(y_pred_dtc_grid,y_test), 3)\n",
    "\n",
    "#Feature Importance\n",
    "imp_ft = pd.DataFrame(data={'Attribute': x_smote.columns, 'Importance': dtc_optimal_model.feature_importances_}).sort_values(by='Importance', ascending=False)\n",
    "dtc_feat = np.array(imp_ft['Attribute'][:3:])\n",
    "\n",
    "#Training time calculation\n",
    "dtc_time=stop-start\n",
    "\n",
    "results = pd.DataFrame([['Decision trees tuned', dtc_acctr, dtc_acc, dtc_prec, dtc_rec, dtc_f1 , dtc_roc, dtc_time, dtc_feat ]],\n",
    "               columns = ['Model', 'Train Accuracy', 'Test Accuracy', 'Precision', 'Recall', 'F1 Score','ROC', 'Training Time(s)','Important Features'])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGJ-gRiYVMCx"
   },
   "source": [
    "### 4. **Random Forest Classifer**\n",
    "\n",
    "\n",
    "Possible parameters to tune:\n",
    "\n",
    "    1. n_estimators in [10, 100, 1000]\n",
    "    2. max_features in [‘sqrt’, ‘log2’]   or max_features [1 to 20]\n",
    "    3. min_samples_split\n",
    "    4. min_samples_leaf\n",
    "    5. max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "R-vfSURrIqpl",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Grid\n",
    "param_distributions = {'n_estimators' : [10, 50, 70],\n",
    "               'max_depth' : [2, 3, 5, 10]}\n",
    "\n",
    "start = time.time()\n",
    "# Create an instance of the RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# Grid search\n",
    "rfc_grid = RandomizedSearchCV(rfc ,param_distributions, n_jobs=-1, random_state=0, cv=5, verbose=1)\n",
    "rfc_grid.fit(x_smote, y_smote)\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Bg4U0X3Iz9O",
    "outputId": "69e5369c-1611-4a25-b243-de9f88785322"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=10, n_estimators=50)\n",
      "{'n_estimators': 50, 'max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "# Displaying best parameters\n",
    "print(rfc_grid.best_estimator_)\n",
    "print(rfc_grid.best_params_)\n",
    "\n",
    "rfc_optimal_model = rfc_grid.best_estimator_\n",
    "\n",
    "#class prediction of y on train and test\n",
    "y_pred_rfc_grid = rfc_optimal_model.predict(x_test)\n",
    "y_train_pred_rfc_grid = rfc_optimal_model.predict(x_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pAoDDAhyJfsw",
    "outputId": "4d625c05-c0ad-45c2-c69f-71a85027fad6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC</th>\n",
       "      <th>Training Time(s)</th>\n",
       "      <th>Important Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest tuned</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.721</td>\n",
       "      <td>13.322136</td>\n",
       "      <td>[PAY_0, MARRIAGE_married, PAY_2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Train Accuracy  Test Accuracy  Precision  Recall  \\\n",
       "0  Random Forest tuned           0.888          0.808      0.441   0.592   \n",
       "\n",
       "   F1 Score    ROC  Training Time(s)                Important Features  \n",
       "0     0.506  0.721         13.322136  [PAY_0, MARRIAGE_married, PAY_2]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting all scores for Random Forest Classifier\n",
    "rfc_acctr = round(accuracy_score(y_train_pred_rfc_grid,y_smote), 3)\n",
    "rfc_acc = round(accuracy_score(y_pred_rfc_grid,y_test), 3)\n",
    "rfc_prec = round(precision_score(y_pred_rfc_grid,y_test), 3)\n",
    "rfc_rec = round(recall_score(y_pred_rfc_grid,y_test), 3)\n",
    "rfc_f1 = round(f1_score(y_pred_rfc_grid,y_test), 3)\n",
    "rfc_roc = round(roc_auc_score(y_pred_rfc_grid,y_test), 3)\n",
    "\n",
    "#Feature Importance\n",
    "imp_ft = pd.DataFrame(data={'Attribute': x_smote.columns, 'Importance': rfc_optimal_model.feature_importances_}).sort_values(by='Importance', ascending=False)\n",
    "rfc_feat = np.array(imp_ft['Attribute'][:3:])\n",
    "\n",
    "#Training time calculation\n",
    "rfc_time=stop-start\n",
    "\n",
    "results = pd.DataFrame([['Random Forest tuned', rfc_acctr, rfc_acc, rfc_prec, rfc_rec, rfc_f1, rfc_roc, rfc_time, rfc_feat]],\n",
    "               columns = ['Model', 'Train Accuracy', 'Test Accuracy', 'Precision', 'Recall', 'F1 Score','ROC', 'Training Time(s)','Important Features'])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYFTO_WbNhKg"
   },
   "source": [
    "### 5. **Gradient Boosting**\n",
    "\n",
    "Possible parameters to tune:\n",
    "\n",
    "1. learning_rate in [0.001, 0.01, 0.1]\n",
    "2. n_estimators [10, 100, 1000]\n",
    "3. subsample in [0.5, 0.7, 1.0]\n",
    "4. max_depth in [2, 7, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "fTt0ddvDeHe2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [0.01, 0.1],\n",
       "                                        &#x27;max_depth&#x27;: [2, 3, 4],\n",
       "                                        &#x27;n_estimators&#x27;: [10, 50, 100]},\n",
       "                   random_state=0, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [0.01, 0.1],\n",
       "                                        &#x27;max_depth&#x27;: [2, 3, 4],\n",
       "                                        &#x27;n_estimators&#x27;: [10, 50, 100]},\n",
       "                   random_state=0, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': [0.01, 0.1],\n",
       "                                        'max_depth': [2, 3, 4],\n",
       "                                        'n_estimators': [10, 50, 100]},\n",
       "                   random_state=0, verbose=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter Grid       #3min\n",
    "param_distributions = {'learning_rate': [0.01, 0.1],\n",
    "              'n_estimators' : [10, 50, 100],\n",
    "              'max_depth' : [2, 3, 4],}\n",
    "\n",
    "start = time.time()\n",
    "gbc = GradientBoostingClassifier()\n",
    "stop = time.time()\n",
    "\n",
    "# Grid search\n",
    "gbc_grid = RandomizedSearchCV(gbc, param_distributions, n_jobs=-1, random_state=0, cv=5, verbose=1)\n",
    "gbc_grid.fit(x_smote, y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U8MSlw_0eHe3",
    "outputId": "d0c00513-d79b-478e-c455-041e84729fc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(max_depth=4)\n",
      "{'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Displaying best parameters\n",
    "print(gbc_grid.best_estimator_)\n",
    "print(gbc_grid.best_params_)\n",
    "\n",
    "gbc_optimal_model = gbc_grid.best_estimator_\n",
    "\n",
    "#class prediction of y on train and test\n",
    "y_pred_gbc_grid = gbc_optimal_model.predict(x_test)\n",
    "y_train_pred_gbc_grid = gbc_optimal_model.predict(x_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iWzKxUCJeHe6",
    "outputId": "6e4c5a11-1235-45bf-a980-4bd10be46cce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC</th>\n",
       "      <th>Training Time(s)</th>\n",
       "      <th>Important Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting Tuned</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>[PAY_0, MARRIAGE_married, SEX_female]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Train Accuracy  Test Accuracy  Precision  Recall  \\\n",
       "0  Gradient Boosting Tuned           0.881           0.81       0.39   0.614   \n",
       "\n",
       "   F1 Score    ROC  Training Time(s)                     Important Features  \n",
       "0     0.477  0.728          0.000073  [PAY_0, MARRIAGE_married, SEX_female]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting all scores for Gradient booster\n",
    "gbc_acctr = round(accuracy_score(y_train_pred_gbc_grid,y_smote), 3)\n",
    "gbc_acc = round(accuracy_score(y_pred_gbc_grid,y_test), 3)\n",
    "gbc_prec = round(precision_score(y_pred_gbc_grid,y_test), 3)\n",
    "gbc_rec = round(recall_score(y_pred_gbc_grid,y_test), 3)\n",
    "gbc_f1 = round(f1_score(y_pred_gbc_grid,y_test), 3)\n",
    "gbc_roc = round(roc_auc_score(y_pred_gbc_grid,y_test), 3)\n",
    "\n",
    "#Feature Importance\n",
    "imp_ft = pd.DataFrame(data={'Attribute': x_smote.columns, 'Importance': gbc_optimal_model.feature_importances_}).sort_values(by='Importance', ascending=False)\n",
    "gbc_feat = np.array(imp_ft['Attribute'][:3:])\n",
    "\n",
    "#Training time calculation\n",
    "gbc_time=stop-start\n",
    "\n",
    "results = pd.DataFrame([['Gradient Boosting Tuned', gbc_acctr, gbc_acc, gbc_prec, gbc_rec, gbc_f1, gbc_roc, gbc_time, gbc_feat]],\n",
    "               columns = ['Model', 'Train Accuracy', 'Test Accuracy', 'Precision', 'Recall', 'F1 Score','ROC', 'Training Time(s)','Important Features'])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HhvEJF0frRc1",
    "tags": []
   },
   "source": [
    "### 6. **XG Boosting**\n",
    "\n",
    "Possible parameters to tune:\n",
    "\n",
    "    1. learning_rate in [0.001, 0.01, 0.1]\n",
    "    2. max_depth [1 to 20]\n",
    "    3. max_leaf_nodes\n",
    "    4. gamma\n",
    "    5. min_child_weight\n",
    "    6. n_estimators in (50, 100, 150]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "3tRn39OpvrgZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Grid\n",
    "param_distributions = {\n",
    "#             'n_estimators' : [50, 100],\n",
    "              'max_depth': [2, 3, 5],\n",
    "#              'learning_rate': [0.1, 0.15],\n",
    "              'gamma': [0.1,0.6,0.8]\n",
    "               }\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "# Create an instance of the XGBClassifier\n",
    "xgb = XGBClassifier(random_state=0, use_label_encoder=False, eval_metric = 'logloss')\n",
    "\n",
    "# Grid search\n",
    "xgb_grid = RandomizedSearchCV(xgb ,param_distributions, n_jobs=-1, random_state=0, cv=2, verbose=1)\n",
    "\n",
    "# fitting model\n",
    "xgb_grid.fit(x_smote,y_smote)\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ioVWpsUvrge",
    "outputId": "063d036f-99f4-49ed-f009-eab658d3a474"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              eval_metric='logloss', gamma=0.8, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_delta_step=0, max_depth=3, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
      "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', use_label_encoder=False,\n",
      "              validate_parameters=1, verbosity=None)\n",
      "{'max_depth': 3, 'gamma': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# Displaying best parameters\n",
    "print(xgb_grid.best_estimator_)\n",
    "print(xgb_grid.best_params_)\n",
    "\n",
    "xgb_optimal_model = xgb_grid.best_estimator_\n",
    "\n",
    "#class prediction of y on train and test\n",
    "y_pred_xgb_grid = xgb_optimal_model.predict(x_test)\n",
    "y_train_pred_xgb_grid = xgb_optimal_model.predict(x_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4fZ6TWT6vrgk",
    "outputId": "3e3675d2-48ba-4ef6-b492-4a0b11c83ee4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC</th>\n",
       "      <th>Training Time(s)</th>\n",
       "      <th>Important Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XG Boosting Tuned</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.733</td>\n",
       "      <td>635.614341</td>\n",
       "      <td>[MARRIAGE_married, PAY_0, EDUCATION_university]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  Train Accuracy  Test Accuracy  Precision  Recall  \\\n",
       "0  XG Boosting Tuned           0.885          0.812      0.388   0.625   \n",
       "\n",
       "   F1 Score    ROC  Training Time(s)  \\\n",
       "0     0.479  0.733        635.614341   \n",
       "\n",
       "                                Important Features  \n",
       "0  [MARRIAGE_married, PAY_0, EDUCATION_university]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting all scores for XG Boosting Classifier\n",
    "xgb_acctr = round(accuracy_score(y_train_pred_xgb_grid,y_smote), 3)\n",
    "xgb_acc = round(accuracy_score(y_pred_xgb_grid,y_test), 3)\n",
    "xgb_prec = round(precision_score(y_pred_xgb_grid,y_test), 3)\n",
    "xgb_rec = round(recall_score(y_pred_xgb_grid,y_test), 3)\n",
    "xgb_f1 = round(f1_score(y_pred_xgb_grid,y_test), 3)\n",
    "xgb_roc = round(roc_auc_score(y_pred_xgb_grid,y_test), 3)\n",
    "\n",
    "#Feature Importance\n",
    "imp_ft = pd.DataFrame(data={'Attribute': x_smote.columns, 'Importance': xgb_optimal_model.feature_importances_}).sort_values(by='Importance', ascending=False)\n",
    "xgb_feat = np.array(imp_ft['Attribute'][:3:])\n",
    "\n",
    "#Training time calculation\n",
    "xgb_time=stop-start\n",
    "\n",
    "results = pd.DataFrame([['XG Boosting Tuned', xgb_acctr, xgb_acc, xgb_prec, xgb_rec, xgb_f1, xgb_roc, xgb_time, xgb_feat]],\n",
    "               columns = ['Model', 'Train Accuracy', 'Test Accuracy', 'Precision', 'Recall', 'F1 Score','ROC', 'Training Time(s)','Important Features'])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. **ADA Boosting**\n",
    "\n",
    "Possible parameters to tune:\n",
    "\n",
    "    1. learning_rate in [0.001, 0.01, 0.1]\n",
    "    2. base_estimator\n",
    "    3. n_estimators in [50, 100, 150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "3tRn39OpvrgZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Grid\n",
    "param_distributions = {'learning_rate': [0.001, 0.01, 0.1, 0.5],\n",
    "              'n_estimators' : [50, 100, 150]}\n",
    "\n",
    "start = time.time()\n",
    "ada = AdaBoostClassifier()\n",
    "\n",
    "ada_grid = RandomizedSearchCV(ada ,param_distributions, n_jobs=-1, random_state=0, cv=5, verbose=1)\n",
    "\n",
    "# fitting model\n",
    "ada_grid.fit(x_smote,y_smote)\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ioVWpsUvrge",
    "outputId": "063d036f-99f4-49ed-f009-eab658d3a474"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(learning_rate=0.5, n_estimators=150)\n",
      "{'n_estimators': 150, 'learning_rate': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# Displaying best parameters\n",
    "print(ada_grid.best_estimator_)\n",
    "print(ada_grid.best_params_)\n",
    "\n",
    "ada_optimal_model = ada_grid.best_estimator_\n",
    "\n",
    "#class prediction of y on train and test\n",
    "y_pred_ada_grid = ada_optimal_model.predict(x_test)\n",
    "y_train_pred_ada_grid = ada_optimal_model.predict(x_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4fZ6TWT6vrgk",
    "outputId": "3e3675d2-48ba-4ef6-b492-4a0b11c83ee4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC</th>\n",
       "      <th>Training Time(s)</th>\n",
       "      <th>Important Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADA Boosting tuned</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.721</td>\n",
       "      <td>47.734555</td>\n",
       "      <td>[SEX_female, MARRIAGE_married, EDUCATION_unive...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Train Accuracy  Test Accuracy  Precision  Recall  \\\n",
       "0  ADA Boosting tuned           0.863          0.806      0.392     0.6   \n",
       "\n",
       "   F1 Score    ROC  Training Time(s)  \\\n",
       "0     0.474  0.721         47.734555   \n",
       "\n",
       "                                  Important Features  \n",
       "0  [SEX_female, MARRIAGE_married, EDUCATION_unive...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting all scores for Ada Boosting\n",
    "ada_acctr = round(accuracy_score(y_train_pred_ada_grid,y_smote), 3)\n",
    "ada_acc = round(accuracy_score(y_pred_ada_grid,y_test), 3)\n",
    "ada_prec = round(precision_score(y_pred_ada_grid,y_test), 3)\n",
    "ada_rec = round(recall_score(y_pred_ada_grid,y_test), 3)\n",
    "ada_f1 = round(f1_score(y_pred_ada_grid,y_test), 3)\n",
    "ada_roc = round(roc_auc_score(y_pred_ada_grid,y_test), 3)\n",
    "\n",
    "#Feature Importance\n",
    "imp_ft = pd.DataFrame(data={'Attribute': x_smote.columns, 'Importance': ada_optimal_model.feature_importances_}).sort_values(by='Importance', ascending=False)\n",
    "ada_feat = np.array(imp_ft['Attribute'][:3:])\n",
    "\n",
    "#Training time calculation\n",
    "ada_time=stop-start\n",
    "\n",
    "results = pd.DataFrame([['ADA Boosting tuned', ada_acctr, ada_acc, ada_prec, ada_rec, ada_f1, ada_roc, ada_time, ada_feat]],\n",
    "               columns = ['Model', 'Train Accuracy', 'Test Accuracy', 'Precision', 'Recall', 'F1 Score','ROC', 'Training Time(s)','Important Features'])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. **Bagging**\n",
    "\n",
    "Possible parameters to tune:\n",
    "\n",
    "    1. learning_rate in [0.001, 0.01, 0.1]\n",
    "    2. max_features\n",
    "    3. n_estimators in [10,50, 100, 150]\n",
    "    4. max_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "3tRn39OpvrgZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Grid\n",
    "param_distributions = {'n_estimators' : [5, 10, 50, 150, 300],\n",
    "               'max_features' : [2, 5, 10, 15],\n",
    "               'max_samples' : [0.05, 0.1, 0.2]}\n",
    "\n",
    "start = time.time()\n",
    "bag = BaggingClassifier()\n",
    "\n",
    "bag_grid = RandomizedSearchCV(bag ,param_distributions, n_jobs=-1, random_state=0, cv=5, verbose=1)\n",
    "\n",
    "bag_grid.fit(x_smote,y_smote)\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ioVWpsUvrge",
    "outputId": "063d036f-99f4-49ed-f009-eab658d3a474"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(max_features=5, max_samples=0.2, n_estimators=150)\n",
      "{'n_estimators': 150, 'max_samples': 0.2, 'max_features': 5}\n"
     ]
    }
   ],
   "source": [
    "# Displaying best parameters\n",
    "print(bag_grid.best_estimator_)\n",
    "print(bag_grid.best_params_)\n",
    "\n",
    "bag_optimal_model = bag_grid.best_estimator_\n",
    "\n",
    "#class prediction of y on train and test\n",
    "y_pred_bag_grid = bag_optimal_model.predict(x_test)\n",
    "y_train_pred_bag_grid = bag_optimal_model.predict(x_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4fZ6TWT6vrgk",
    "outputId": "3e3675d2-48ba-4ef6-b492-4a0b11c83ee4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC</th>\n",
       "      <th>Training Time(s)</th>\n",
       "      <th>Important Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagging classifier tuned</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.717</td>\n",
       "      <td>32.704007</td>\n",
       "      <td>[No coefficients available]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  Train Accuracy  Test Accuracy  Precision  Recall  \\\n",
       "0  Bagging classifier tuned           0.909            0.8      0.283   0.611   \n",
       "\n",
       "   F1 Score    ROC  Training Time(s)           Important Features  \n",
       "0     0.387  0.717         32.704007  [No coefficients available]  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting all scores for Logistic Regression\n",
    "bag_acctr = round(accuracy_score(y_train_pred_bag_grid,y_smote), 3)\n",
    "bag_acc = round(accuracy_score(y_pred_bag_grid,y_test), 3)\n",
    "bag_prec = round(precision_score(y_pred_bag_grid,y_test), 3)\n",
    "bag_rec = round(recall_score(y_pred_bag_grid,y_test), 3)\n",
    "bag_f1 = round(f1_score(y_pred_bag_grid,y_test), 3)\n",
    "bag_roc = round(roc_auc_score(y_pred_bag_grid,y_test), 3)\n",
    "\n",
    "#Feature Importance\n",
    "bag_feat = ['No coefficients available']\n",
    "\n",
    "#Training time calculation\n",
    "bag_time=stop-start\n",
    "\n",
    "results = pd.DataFrame([['Bagging classifier tuned', bag_acctr, bag_acc, bag_prec, bag_rec, bag_f1, bag_roc, bag_time, bag_feat]],\n",
    "               columns = ['Model', 'Train Accuracy', 'Test Accuracy', 'Precision', 'Recall', 'F1 Score','ROC', 'Training Time(s)','Important Features'])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Ou4AtBbb5bi"
   },
   "source": [
    "### **Final Model Comparision**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "BrVe-hXPcHzw"
   },
   "outputs": [],
   "source": [
    "grid_classifiers = ['Optimal Logistic Regression', 'Optimal K Nearest Neighbors', 'Optimal Decision Tree', 'Optimal Random Forest',\n",
    "                  'Optimal Gradient Boosting', 'Optimal XG Boosting', 'Optimal Ada Boosting', 'Optimal Bagging']\n",
    "\n",
    "grid_train_accuracy =  [log_acctr, knn_acctr, dtc_acctr, rfc_acctr, gbc_acctr, xgb_acctr, ada_acctr, bag_acctr]\n",
    "grid_test_accuracy =   [log_acc, knn_acc, dtc_acc, rfc_acc, gbc_acc, xgb_acc, ada_acc, bag_acc]\n",
    "grid_precision_score = [log_prec, knn_prec, dtc_prec, rfc_prec, gbc_prec, xgb_prec, ada_prec, bag_prec]\n",
    "grid_recall_score =    [log_rec, knn_rec, dtc_rec, rfc_rec, gbc_rec, xgb_rec, ada_rec, bag_rec]\n",
    "grid_f1_score =        [log_f1, knn_f1, dtc_f1, rfc_f1, gbc_f1, xgb_f1, ada_f1, bag_f1]\n",
    "grid_auc_score =       [log_roc, knn_roc, dtc_roc, rfc_roc, gbc_roc, xgb_roc, ada_roc, bag_roc]\n",
    "training_time=[log_time, knn_time, dtc_time, rfc_time, gbc_time, xgb_time, ada_time, bag_time]\n",
    "feature_imp = [log_feat, knn_feat, dtc_feat, rfc_feat, gbc_feat, xgb_feat, ada_feat, bag_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Training Time(s)</th>\n",
       "      <th>Important Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Optimal Logistic Regression</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.801523</td>\n",
       "      <td>[AGE_median, PAY_0, PAY_2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Optimal K Nearest Neighbors</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.564</td>\n",
       "      <td>9.038884</td>\n",
       "      <td>[No coefficients available]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Optimal Decision Tree</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.704</td>\n",
       "      <td>2.244369</td>\n",
       "      <td>[PAY_0, MARRIAGE_married, SEX_female]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Optimal Random Forest</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.721</td>\n",
       "      <td>13.322136</td>\n",
       "      <td>[PAY_0, MARRIAGE_married, PAY_2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Optimal Gradient Boosting</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>[PAY_0, MARRIAGE_married, SEX_female]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Optimal XG Boosting</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.733</td>\n",
       "      <td>635.614341</td>\n",
       "      <td>[MARRIAGE_married, PAY_0, EDUCATION_university]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Optimal Ada Boosting</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.721</td>\n",
       "      <td>47.734555</td>\n",
       "      <td>[SEX_female, MARRIAGE_married, EDUCATION_unive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Optimal Bagging</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.717</td>\n",
       "      <td>32.704007</td>\n",
       "      <td>[No coefficients available]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Classifier  Train Accuracy  Test Accuracy  Precision  \\\n",
       "0  Optimal Logistic Regression           0.632          0.557      0.738   \n",
       "1  Optimal K Nearest Neighbors           0.798          0.624      0.521   \n",
       "2        Optimal Decision Tree           0.870          0.798      0.394   \n",
       "3        Optimal Random Forest           0.888          0.808      0.441   \n",
       "4    Optimal Gradient Boosting           0.881          0.810      0.390   \n",
       "5          Optimal XG Boosting           0.885          0.812      0.388   \n",
       "6         Optimal Ada Boosting           0.863          0.806      0.392   \n",
       "7              Optimal Bagging           0.909          0.800      0.283   \n",
       "\n",
       "   Recall  F1 Score    AUC  Training Time(s)  \\\n",
       "0   0.299     0.426  0.585          5.801523   \n",
       "1   0.301     0.382  0.564          9.038884   \n",
       "2   0.567     0.465  0.704          2.244369   \n",
       "3   0.592     0.506  0.721         13.322136   \n",
       "4   0.614     0.477  0.728          0.000073   \n",
       "5   0.625     0.479  0.733        635.614341   \n",
       "6   0.600     0.474  0.721         47.734555   \n",
       "7   0.611     0.387  0.717         32.704007   \n",
       "\n",
       "                                  Important Features  \n",
       "0                         [AGE_median, PAY_0, PAY_2]  \n",
       "1                        [No coefficients available]  \n",
       "2              [PAY_0, MARRIAGE_married, SEX_female]  \n",
       "3                   [PAY_0, MARRIAGE_married, PAY_2]  \n",
       "4              [PAY_0, MARRIAGE_married, SEX_female]  \n",
       "5    [MARRIAGE_married, PAY_0, EDUCATION_university]  \n",
       "6  [SEX_female, MARRIAGE_married, EDUCATION_unive...  \n",
       "7                        [No coefficients available]  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_df = pd.DataFrame({'Classifier':grid_classifiers, 'Train Accuracy': grid_train_accuracy, 'Test Accuracy': grid_test_accuracy, \n",
    "                           'Precision': grid_precision_score, 'Recall': grid_recall_score, 'F1 Score': grid_f1_score , \n",
    "                           'AUC': grid_auc_score, 'Training Time(s)':training_time, 'Important Features':feature_imp})\n",
    "compare_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FlrzETAepQnd"
   },
   "source": [
    "### **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dKRwJyKl3VR"
   },
   "source": [
    "* After cross validation and hyperparameter tunning, Ensemble algorithms shows better performance compared to other models\n",
    "\n",
    "- The hyperparameter tuned optimized algorithms show improved performance compared to the Baseline models\n",
    "\n",
    "* Hyperparameter tuning has also reduced the overfitting issue in Random forest & Decision tree models\n",
    "\n",
    "* One can try tuning other hyperparameters, passing different ranges of values and a different CV fold to check for any further improvement in the model performance"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Credit Card Default Prediction - Amol.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
